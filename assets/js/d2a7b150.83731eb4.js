"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[145],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>g});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=o.createContext({}),u=function(e){var t=o.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},s=function(e){var t=u(e.components);return o.createElement(p.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,p=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),m=u(n),d=r,g=m["".concat(p,".").concat(d)]||m[d]||c[d]||a;return n?o.createElement(g,i(i({ref:t},s),{},{components:n})):o.createElement(g,i({ref:t},s))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=d;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l[m]="string"==typeof e?e:r,i[1]=l;for(var u=2;u<a;u++)i[u]=n[u];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}d.displayName="MDXCreateElement"},2026:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>c,frontMatter:()=>a,metadata:()=>l,toc:()=>u});var o=n(7462),r=(n(7294),n(3905));const a={},i="Publish model to HuggingFace",l={unversionedId:"guide/experiments/export-trained-model",id:"guide/experiments/export-trained-model",title:"Publish model to HuggingFace",description:"If you\u2019re ready to share your trained model with a broader community, H2O LLM Studio allows you to export the fine-tuned model to Hugging Face with a single click.",source:"@site/docs/guide/experiments/export-trained-model.md",sourceDirName:"guide/experiments",slug:"/guide/experiments/export-trained-model",permalink:"/h2o-llmstudio/guide/experiments/export-trained-model",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"defaultSidebar",previous:{title:"Compare experiments",permalink:"/h2o-llmstudio/guide/experiments/compare-experiments"},next:{title:"FAQs",permalink:"/h2o-llmstudio/faqs"}},p={},u=[{value:"Download a model",id:"download-a-model",level:2}],s={toc:u},m="wrapper";function c(e){let{components:t,...a}=e;return(0,r.kt)(m,(0,o.Z)({},s,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"publish-model-to-huggingface"},"Publish model to HuggingFace"),(0,r.kt)("p",null,"If you\u2019re ready to share your trained model with a broader community, H2O LLM Studio allows you to export the fine-tuned model to ",(0,r.kt)("a",{parentName:"p",href:"https://huggingface.co/"},"Hugging Face")," with a single click."),(0,r.kt)("admonition",{title:"note",type:"info"},(0,r.kt)("p",{parentName:"admonition"},"Before publishing your model to the Hugging Face Hub, you need to have an API key with the write access. To obtain an API token with write access, you can follow the ",(0,r.kt)("a",{parentName:"p",href:"https://huggingface.co/docs/hub/security-tokens"},"instructions provided by Hugging Face"),", which involve creating an account, logging in, and generating an access token with the appropriate permission.")),(0,r.kt)("p",null,"To publish a trained model to Hugging Face Hub:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"On the H2O LLM Studio left-navigation pane, click ",(0,r.kt)("strong",{parentName:"p"},"View experiments"),". You will see the experiments table with a list of all the experiments you have launched so far. ")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click the name of the experiment that you want to export the model.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click ",(0,r.kt)("strong",{parentName:"p"},"Push checkpoint to huggingface"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Enter the ",(0,r.kt)("strong",{parentName:"p"},"Account name")," on Hugging Face that you want to push the model. Leaving it empty will push it to the default user account.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Enter the ",(0,r.kt)("strong",{parentName:"p"},"Huggingface API")," Key with the write access.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click ",(0,r.kt)("strong",{parentName:"p"},"Export"),"."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"export model to hugging face",src:n(7555).Z,width:"2880",height:"1296"})))),(0,r.kt)("h2",{id:"download-a-model"},"Download a model"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Click ",(0,r.kt)("strong",{parentName:"li"},"Download model")," on the ",(0,r.kt)("strong",{parentName:"li"},"View experiments")," page to download the model locally.")),(0,r.kt)("p",null,"Use the following code snippet to utilize the converted model in Jupyter Notebook or Google Colab. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = "path_to_downloaded_model"  # either local folder or huggingface model name\n\n# Important: The prompt needs to be in the same format the model was trained with.\n# You can find an example prompt in the experiment logs.\nprompt = "<|prompt|>How are you?<|endoftext|><|answer|>"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\nmodel.cuda().eval()\n\ninputs = tokenizer(prompt, return_tensors="pt", add_special_tokens=False).to("cuda")\n# generate configuration can be modified to your needs\ntokens = model.generate(\n    **inputs, # Input any question for the model. Ex: "What is the capital of USA?"\n    max_new_tokens=256,\n    temperature=0.3,\n    repetition_penalty=1.2,\n    num_beams=1\n)[0]\ntokens = tokens[inputs["input_ids"].shape[1]:]\nanswer = tokenizer.decode(tokens, skip_special_tokens=True)\nprint(answer)\n')),(0,r.kt)("p",null,"You can enter any question for the model and change the parameters to get different outputs."))}c.isMDXComponent=!0},7555:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/export-model-to-huggingface-751d5a3594cb0f0ddfc8f7716aceafa0.png"}}]);