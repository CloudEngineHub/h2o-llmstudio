"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[624],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>h});var o=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=o.createContext({}),p=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=p(e.components);return o.createElement(s.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},c=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),m=p(n),c=a,h=m["".concat(s,".").concat(c)]||m[c]||u[c]||i;return n?o.createElement(h,r(r({ref:t},d),{},{components:n})):o.createElement(h,r({ref:t},d))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,r=new Array(i);r[0]=c;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[m]="string"==typeof e?e:a,r[1]=l;for(var p=2;p<i;p++)r[p]=n[p];return o.createElement.apply(null,r)}return o.createElement.apply(null,n)}c.displayName="MDXCreateElement"},1410:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>Io,contentTitle:()=>Eo,default:()=>jo,frontMatter:()=>zo,metadata:()=>Ho,toc:()=>Go});var o=n(7462),a=(n(7294),n(3905));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.kt)(r,(0,o.Z)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"It defines the dataset for the experiment."))}l.isMDXComponent=!0;const s={toc:[]},p="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(p,(0,o.Z)({},s,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the problem type of the experiment, which also defines the settings H2O LLM Studio displays for the experiment."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Causal Language Modeling: Used to fine-tune large language models")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Sequence To Sequence Modeling: Used to fine-tune large sequence to sequence models"))))}d.isMDXComponent=!0;const m={toc:[]},u="wrapper";function c(e){let{components:t,...n}=e;return(0,a.kt)(u,(0,o.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the ",(0,a.kt)("inlineCode",{parentName:"p"},".yml")," file that defines the experiment settings. "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio supports a ",(0,a.kt)("inlineCode",{parentName:"li"},".yml")," file import and export functionality. You can download the config settings of finished experiments, make changes, and re-upload them when starting a new experiment in any instance of H2O LLM Studio.")))}c.isMDXComponent=!0;const h={toc:[]},k="wrapper";function g(e){let{components:t,...n}=e;return(0,a.kt)(k,(0,o.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"It defines the name of the experiment."))}g.isMDXComponent=!0;const f={toc:[]},y="wrapper";function v(e){let{components:t,...n}=e;return(0,a.kt)(y,(0,o.Z)({},f,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The ",(0,a.kt)("strong",{parentName:"p"},"LLM Backbone")," option is the most important setting as it sets the pretrained model weights."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Usually, it is good to use smaller architectures for quicker experiments and larger models when aiming for the highest accuracy"),(0,a.kt)("li",{parentName:"ul"},"If possible, leverage backbones pre-trained closely to your use case"),(0,a.kt)("li",{parentName:"ul"},"Any huggingface model can be used here (not limited to the ones in the dropdown list)")))}v.isMDXComponent=!0;var b=n(1953);const x={toc:[]},T="wrapper";function w(e){let{components:t,...n}=e;return(0,a.kt)(T,(0,o.Z)({},x,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Specifies the validation strategy H2O LLM Studio uses for the experiment."),(0,a.kt)("p",null,"To properly assess the performance of your trained models, it is common practice to evaluate it on separate holdout data that the model has not seen during training. H2O LLM Studio allows you to specify different strategies for this task fitting your needs."),(0,a.kt)("p",null,"Options"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Custom holdout validation"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Specifies a separate holdout dataframe."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Automatic holdout validation"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Allows to specify a holdout validation sample size that is automatically generated.")))))}w.isMDXComponent=!0;const D={toc:[]},M="wrapper";function L(e){let{components:t,...n}=e;return(0,a.kt)(M,(0,o.Z)({},D,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines an optional relative size of the holdout validation set. H2O LLM Studio do automatically sample the selected\npercentage from the full training data, and build a holdout dataset that the model is validated on."))}L.isMDXComponent=!0;const N={toc:[]},S="wrapper";function X(e){let{components:t,...n}=e;return(0,a.kt)(S,(0,o.Z)({},N,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the percentage of the data to use for the experiment. The default percentage is 100% (1)."),(0,a.kt)("p",null,"Changing the default value can significantly increase the training speed. Still, it might lead to a substantially poor accuracy value. Using 100% (1) of the data for final models is highly recommended."))}X.isMDXComponent=!0;var C=n(8973),O=n(4396),P=n(5661);const Z={toc:[]},A="wrapper";function z(e){let{components:t,...n}=e;return(0,a.kt)(A,(0,o.Z)({},Z,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Optional text to prepend to each prompt."))}z.isMDXComponent=!0;const E={toc:[]},H="wrapper";function I(e){let{components:t,...n}=e;return(0,a.kt)(H,(0,o.Z)({},E,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Optional text to append to each prompt / prepend to each answer."))}I.isMDXComponent=!0;const G={toc:[]},R="wrapper";function q(e){let{components:t,...n}=e;return(0,a.kt)(R,(0,o.Z)({},G,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Use adaptive KL control, otherwise linear."))}q.isMDXComponent=!0;const W={toc:[]},U="wrapper";function j(e){let{components:t,...n}=e;return(0,a.kt)(U,(0,o.Z)({},W,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Adds EOS token at end of prompt."))}j.isMDXComponent=!0;const K={toc:[]},B="wrapper";function F(e){let{components:t,...n}=e;return(0,a.kt)(B,(0,o.Z)({},K,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Adds EOS token at end of answer."))}F.isMDXComponent=!0;const _={toc:[]},V="wrapper";function Y(e){let{components:t,...n}=e;return(0,a.kt)(V,(0,o.Z)({},_,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Whether to mask the prompt labels during training and only train on the loss of the answer."))}Y.isMDXComponent=!0;const Q={toc:[]},J="wrapper";function $(e){let{components:t,...n}=e;return(0,a.kt)(J,(0,o.Z)({},Q,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The maximum sequence length of the prompt to use during training. In case of chained samples, this max length refers to a single prompt length in the chain."))}$.isMDXComponent=!0;const ee={toc:[]},te="wrapper";function ne(e){let{components:t,...n}=e;return(0,a.kt)(te,(0,o.Z)({},ee,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The maximum sequence length of the answer to use during training. In case of chained samples, this max length refers to a single answer length in the chain."))}ne.isMDXComponent=!0;const oe={toc:[]},ae="wrapper";function ie(e){let{components:t,...n}=e;return(0,a.kt)(ae,(0,o.Z)({},oe,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the maximum length of the input sequence H2O LLM Studio uses during model training. In other words, this setting specifies the maximum number of tokens an input text is transformed for model training."),(0,a.kt)("p",null,"A higher token count leads to higher memory usage that slows down training while increasing the probability of obtaining a higher accuracy value."),(0,a.kt)("p",null,"In case of Causal Language Modeling, this includes both prompt and answer, or all prompts and answers in case of chained samples. "),(0,a.kt)("p",null,"In Sequence to Sequence Modeling, this refers to the length of the prompt, or the length of a full chained sample."))}ie.isMDXComponent=!0;const re={toc:[]},le="wrapper";function se(e){let{components:t,...n}=e;return(0,a.kt)(le,(0,o.Z)({},re,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Adds system, prompt and answer tokens as new tokens to the tokenizer. It is recommended to also set ",(0,a.kt)("inlineCode",{parentName:"p"},"Force Embedding Gradients")," in this case."))}se.isMDXComponent=!0;const pe={toc:[]},de="wrapper";function me(e){let{components:t,...n}=e;return(0,a.kt)(de,(0,o.Z)({},pe,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the padding quantile H2O LLM Studio uses to select the maximum token length per batch. H2O LLM Studio performs padding of shorter sequences up to the specified padding quantile instead of the selected ",(0,a.kt)("strong",{parentName:"p"},"Max length"),". H2O LLM Studio truncates longer sequences."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Lowering the quantile can significantly increase training runtime and reduce memory usage in unevenly distributed sequence lengths but can hurt performance "),(0,a.kt)("li",{parentName:"ul"},"The setting depends on the batch size and should be adjusted accordingly "),(0,a.kt)("li",{parentName:"ul"},"No padding is done in inference, and the selected ",(0,a.kt)("strong",{parentName:"li"},"Max Length")," is guaranteed"),(0,a.kt)("li",{parentName:"ul"},"Setting to 0 disables padding")))}me.isMDXComponent=!0;const ue={toc:[]},ce="wrapper";function he(e){let{components:t,...n}=e;return(0,a.kt)(ce,(0,o.Z)({},ue,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Whether or not to use a Fast tokenizer if possible. Some LLM backbones only offer certain types of tokenizers and changing this setting might be needed."))}he.isMDXComponent=!0;const ke={toc:[]},ge="wrapper";function fe(e){let{components:t,...n}=e;return(0,a.kt)(ge,(0,o.Z)({},ke,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The datatype of the weights in the LLM backbone."))}fe.isMDXComponent=!0;const ye={toc:[]},ve="wrapper";function be(e){let{components:t,...n}=e;return(0,a.kt)(ve,(0,o.Z)({},ye,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Determines whether H2O LLM Studio activates gradient checkpointing (GC) when training the model. Starting GC reduces the video random access memory (VRAM) footprint at the cost of a longer runtime (an additional forward pass). Turning ",(0,a.kt)("strong",{parentName:"p"},"On")," GC enables it during the training process."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Caution"),"\nGradient checkpointing is an experimental setting that is not compatible with all backbones or all other settings."),(0,a.kt)("p",null,"Activating ",(0,a.kt)("em",{parentName:"p"},"GC")," comes at the cost of a longer training time; for that reason, try training without ",(0,a.kt)("em",{parentName:"p"},"GC")," first and only activate when experiencing ",(0,a.kt)("em",{parentName:"p"},"GPU out-of-memory (OOM)")," errors."))}be.isMDXComponent=!0;const xe={toc:[]},Te="wrapper";function we(e){let{components:t,...n}=e;return(0,a.kt)(Te,(0,o.Z)({},xe,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Whether to force the computation of gradients for the input embeddings during training. Useful for LORA."))}we.isMDXComponent=!0;const De={toc:[]},Me="wrapper";function Le(e){let{components:t,...n}=e;return(0,a.kt)(Me,(0,o.Z)({},De,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the custom dropout rate H2O LLM Studio uses for intermediate layers in the transformer model."))}Le.isMDXComponent=!0;const Ne={toc:[]},Se="wrapper";function Xe(e){let{components:t,...n}=e;return(0,a.kt)(Se,(0,o.Z)({},Ne,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Allows you to specify a local path to the pretrained weights."))}Xe.isMDXComponent=!0;const Ce={toc:[]},Oe="wrapper";function Pe(e){let{components:t,...n}=e;return(0,a.kt)(Oe,(0,o.Z)({},Ce,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the algorithm or method (optimizer) to use for model training. The selected algorithm or method defines how the model should change the attributes of the neural network, such as weights and learning rate. Optimizers solve optimization problems and make more accurate updates to attributes to reduce learning losses."),(0,a.kt)("p",null,"Options:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Adadelta"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"To learn about Adadelta, see ",(0,a.kt)("a",{href:"https://arxiv.org/abs/1212.5701",target:"_blank"},"ADADELTA: An Adaptive Learning Rate Method"),". "))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Adam"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"To learn about Adam, see ",(0,a.kt)("a",{href:"https://arxiv.org/abs/1412.6980",target:"_blank"},"Adam: A Method for Stochastic Optimization"),". "))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"AdamW"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"To learn about AdamW, see ",(0,a.kt)("a",{href:"https://arxiv.org/abs/1711.05101",target:"_blank"},"Decoupled Weight Decay Regularization"),"."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"AdamW8bit"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"To learn about AdamW, see ",(0,a.kt)("a",{href:"https://arxiv.org/abs/1711.05101",target:"_blank"},"Decoupled Weight Decay Regularization"),"."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"RMSprop")," ",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"To learn about RMSprop, see ",(0,a.kt)("a",{href:"https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf",target:"_blank"},"Neural Networks for Machine Learning"),"."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"SGD")," ",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio uses a stochastic gradient descent optimizer.")))))}Pe.isMDXComponent=!0;const Ze={toc:[]},Ae="wrapper";function ze(e){let{components:t,...n}=e;return(0,a.kt)(Ae,(0,o.Z)({},Ze,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the learning rate H2O LLM Studio uses when training the model, specifically when updating the neural network's weights. The learning rate is the speed at which the model updates its weights after processing each mini-batch of data."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Learning rate is an important setting to tune as it balances under- and overfitting."),(0,a.kt)("li",{parentName:"ul"},"The number of epochs highly impacts the optimal value of the learning rate.")))}ze.isMDXComponent=!0;const Ee={toc:[]},He="wrapper";function Ie(e){let{components:t,...n}=e;return(0,a.kt)(He,(0,o.Z)({},Ee,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the number of training examples a mini-batch uses during an iteration of the training model to estimate the error gradient before updating the model weights. ",(0,a.kt)("strong",{parentName:"p"},"Batch size")," defines the batch size used per a single GPU."),(0,a.kt)("p",null,"During model training, the training data is packed into mini-batches of a fixed size."))}Ie.isMDXComponent=!0;const Ge={toc:[]},Re="wrapper";function qe(e){let{components:t,...n}=e;return(0,a.kt)(Re,(0,o.Z)({},Ge,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the number of epochs to train the model. In other words, it specifies the number of times the learning algorithm goes through the entire training dataset."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The ",(0,a.kt)("strong",{parentName:"li"},"Epochs")," setting is an important setting to tune because it balances under- and overfitting."),(0,a.kt)("li",{parentName:"ul"},"The learning rate highly impacts the optimal value of the epochs."),(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio enables you to utilize a pre-trained model trained on zero epochs (where H2O LLM Studio does not train the model and the pretrained model (experiment) can be evaluated as-is):")))}qe.isMDXComponent=!0;const We={toc:[]},Ue="wrapper";function je(e){let{components:t,...n}=e;return(0,a.kt)(Ue,(0,o.Z)({},We,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the learning rate schedule H2O LLM Studio utilizes during model training. Specifying a learning rate schedule prevents the learning rate from staying the same. Instead, a learning rate schedule causes the learning rate to change over iterations, typically decreasing the learning rate to achieve a better model performance and training convergence."),(0,a.kt)("p",null,"Options"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Constant"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio applies a constant learning rate during the training process."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Cosine"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio applies a cosine learning rate that follows the values of the cosine function."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Linear"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio applies a linear learning rate that decreases the learning rate linearly.")))))}je.isMDXComponent=!0;const Ke={toc:[]},Be="wrapper";function Fe(e){let{components:t,...n}=e;return(0,a.kt)(Be,(0,o.Z)({},Ke,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the number of epochs to warm up the learning rate where the learning rate should increase linearly from 0 to the desired learning rate. Can be a fraction of an epoch."))}Fe.isMDXComponent=!0;const _e={toc:[]},Ve="wrapper";function Ye(e){let{components:t,...n}=e;return(0,a.kt)(Ve,(0,o.Z)({},_e,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the weight decay that H2O LLM Studio uses for the optimizer during model training."),(0,a.kt)("p",null,"Weight decay is a regularization technique that adds an L2 norm of all model weights to the loss function while increasing the probability of improving the model generalization."))}Ye.isMDXComponent=!0;const Qe={toc:[]},Je="wrapper";function $e(e){let{components:t,...n}=e;return(0,a.kt)(Je,(0,o.Z)({},Qe,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the maximum norm of the gradients H2O LLM Studio specifies during model training. Defaults to ",(0,a.kt)("strong",{parentName:"p"},"0"),", no clipping. When a value greater than 0 is specified, H2O LLM Studio modifies the gradients during model training. H2O LLM Studio uses the specified value as an upper limit for the norm of the gradients, calculated using the Euclidean norm over all gradients per batch."),(0,a.kt)("p",null,"This setting can help model convergence when extreme gradient values cause high volatility of weight updates."))}$e.isMDXComponent=!0;const et={toc:[]},tt="wrapper";function nt(e){let{components:t,...n}=e;return(0,a.kt)(tt,(0,o.Z)({},et,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the number of gradient accumulations before H2O LLM Studio updates the neural network weights during model training."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Grad accumulation can be beneficial if only small batches are selected for training. With gradient accumulation, the loss and gradients are calculated after each batch, but it waits for the selected accumulations before updating the model weights. You can control the batch size through the ",(0,a.kt)("strong",{parentName:"li"},"Batch size")," setting."),(0,a.kt)("li",{parentName:"ul"},"Changing the default value of ",(0,a.kt)("em",{parentName:"li"},"Grad Accumulation")," might require adjusting the learning rate and batch size.")))}nt.isMDXComponent=!0;const ot={toc:[]},at="wrapper";function it(e){let{components:t,...n}=e;return(0,a.kt)(at,(0,o.Z)({},ot,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Whether to use low rank approximations (LoRA) during training."))}it.isMDXComponent=!0;const rt={toc:[]},lt="wrapper";function st(e){let{components:t,...n}=e;return(0,a.kt)(lt,(0,o.Z)({},rt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The dimension of the matrix decomposition used in LoRA."))}st.isMDXComponent=!0;const pt={toc:[]},dt="wrapper";function mt(e){let{components:t,...n}=e;return(0,a.kt)(dt,(0,o.Z)({},pt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The scaling factor for the lora weights."))}mt.isMDXComponent=!0;const ut={toc:[]},ct="wrapper";function ht(e){let{components:t,...n}=e;return(0,a.kt)(ct,(0,o.Z)({},ut,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The probability of applying dropout to the LoRA weights during training."))}ht.isMDXComponent=!0;const kt={toc:[]},gt="wrapper";function ft(e){let{components:t,...n}=e;return(0,a.kt)(gt,(0,o.Z)({},kt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The modules in the model to apply the LoRA approximation to. Defaults to the attention matrix."))}ft.isMDXComponent=!0;const yt={toc:[]},vt="wrapper";function bt(e){let{components:t,...n}=e;return(0,a.kt)(vt,(0,o.Z)({},yt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Determines if H2O LLM Studio should save the model weights of the epoch exhibiting the best validation metric. When turned ",(0,a.kt)("strong",{parentName:"p"},"On"),", H2O LLM Studio saves the model weights for the epoch exhibiting the best validation metric. When turned ",(0,a.kt)("strong",{parentName:"p"},"Off"),", H2O LLM Studio saves the model weights after the last epoch is executed."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"This setting should be turned ",(0,a.kt)("strong",{parentName:"li"},"On")," with care as it has the potential to lead to overfitting of the validation data. "),(0,a.kt)("li",{parentName:"ul"},"The default goal should be to attempt to tune models so that the last or very last epoch is the best epoch.  "),(0,a.kt)("li",{parentName:"ul"},"Suppose an evident decline for later epochs is observed in logging. In that case, it is usually better to adjust hyperparameters, such as reducing the number of epochs or increasing regularization, instead of turning this setting ",(0,a.kt)("strong",{parentName:"li"},"On"),".")))}bt.isMDXComponent=!0;const xt={toc:[]},Tt="wrapper";function wt(e){let{components:t,...n}=e;return(0,a.kt)(Tt,(0,o.Z)({},xt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the number of epochs H2O LLM Studio uses before each validation loop for model training. In other words, it determines the frequency (in a number of epochs) to run the model evaluation on the validation data."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Increasing the number of ",(0,a.kt)("em",{parentName:"li"},"Evaluation Epochs")," can speed up an experiment."),(0,a.kt)("li",{parentName:"ul"},"The ",(0,a.kt)("strong",{parentName:"li"},"Evaluation epochs")," setting is available only if the following setting is turned ",(0,a.kt)("strong",{parentName:"li"},"Off"),": ",(0,a.kt)("strong",{parentName:"li"},"Save Best Checkpoint"),". "),(0,a.kt)("li",{parentName:"ul"},"Can be a fraction of an epoch")))}wt.isMDXComponent=!0;const Dt={toc:[]},Mt="wrapper";function Lt(e){let{components:t,...n}=e;return(0,a.kt)(Mt,(0,o.Z)({},Dt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This option lets you evaluate the model before training, which can help you judge the quality of the LLM backbone before fine-tuning."))}Lt.isMDXComponent=!0;const Nt={toc:[]},St="wrapper";function Xt(e){let{components:t,...n}=e;return(0,a.kt)(St,(0,o.Z)({},Nt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines whether the model should use the entire train and validation dataset during model training. When turned ",(0,a.kt)("strong",{parentName:"p"},"On"),", H2O LLM Studio uses the whole train dataset and validation data to train the model."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio also evaluates the model on the provided validation fold. Validation is always only on the provided validation fold."),(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio uses both datasets for model training if you provide a train and validation dataset.",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"To define a training dataset, use the ",(0,a.kt)("strong",{parentName:"li"},"Train dataframe")," setting."),(0,a.kt)("li",{parentName:"ul"},"To define a validation dataset, use the ",(0,a.kt)("strong",{parentName:"li"},"Validation dataframe")," setting."))),(0,a.kt)("li",{parentName:"ul"},"The ",(0,a.kt)("strong",{parentName:"li"},"Train validation data")," setting is only available if you turned the ",(0,a.kt)("strong",{parentName:"li"},"Save best checkpoint")," setting ",(0,a.kt)("strong",{parentName:"li"},"Off"),"."),(0,a.kt)("li",{parentName:"ul"},"Turning ",(0,a.kt)("strong",{parentName:"li"},"On")," the ",(0,a.kt)("strong",{parentName:"li"},"Train validation data")," setting should produce a model that you can expect to perform better because H2O LLM Studio trained the model on more data. Though, also note that using the entire train dataset and validation dataset generally causes the model's accuracy to be ",(0,a.kt)("em",{parentName:"li"},"overstated")," as information from the validation data is incorporated into the model during the training process.")))}Xt.isMDXComponent=!0;const Ct={toc:[]},Ot="wrapper";function Pt(e){let{components:t,...n}=e;return(0,a.kt)(Ot,(0,o.Z)({},Ct,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Toggle to enable Reinforcement Learning with Human Feedback."))}Pt.isMDXComponent=!0;const Zt={toc:[]},At="wrapper";function zt(e){let{components:t,...n}=e;return(0,a.kt)(At,(0,o.Z)({},Zt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The ",(0,a.kt)("strong",{parentName:"p"},"Reward Model")," option is gives control over the models weights that shall be used to score the active LLM during RLHF training."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Any suited huggingface model can be used here (not limited to the ones in the dropdown list)")))}zt.isMDXComponent=!0;const Et={toc:[]},Ht="wrapper";function It(e){let{components:t,...n}=e;return(0,a.kt)(Ht,(0,o.Z)({},Et,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Initial KL penalty coefficient (used for adaptive and linear control)."))}It.isMDXComponent=!0;const Gt={toc:[]},Rt="wrapper";function qt(e){let{components:t,...n}=e;return(0,a.kt)(Rt,(0,o.Z)({},Gt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Target KL value for adaptive KL control."))}qt.isMDXComponent=!0;const Wt={toc:[]},Ut="wrapper";function jt(e){let{components:t,...n}=e;return(0,a.kt)(Ut,(0,o.Z)({},Wt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Horizon for adaptive KL control."))}jt.isMDXComponent=!0;const Kt={toc:[]},Bt="wrapper";function Ft(e){let{components:t,...n}=e;return(0,a.kt)(Bt,(0,o.Z)({},Kt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Gamma parameter for advantage calculation."))}Ft.isMDXComponent=!0;const _t={toc:[]},Vt="wrapper";function Yt(e){let{components:t,...n}=e;return(0,a.kt)(Vt,(0,o.Z)({},_t,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Lambda parameter for advantage calculation."))}Yt.isMDXComponent=!0;const Qt={toc:[]},Jt="wrapper";function $t(e){let{components:t,...n}=e;return(0,a.kt)(Jt,(0,o.Z)({},Qt,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Range for clipping in PPO policy gradient loss."))}$t.isMDXComponent=!0;const en={toc:[]},tn="wrapper";function nn(e){let{components:t,...n}=e;return(0,a.kt)(tn,(0,o.Z)({},en,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Range for clipping values in loss calculation."))}nn.isMDXComponent=!0;const on={toc:[]},an="wrapper";function rn(e){let{components:t,...n}=e;return(0,a.kt)(an,(0,o.Z)({},on,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Scaling factor for value loss."))}rn.isMDXComponent=!0;const ln={toc:[]},sn="wrapper";function pn(e){let{components:t,...n}=e;return(0,a.kt)(sn,(0,o.Z)({},ln,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Number of optimisation epochs per batch of samples."))}pn.isMDXComponent=!0;const dn={toc:[]},mn="wrapper";function un(e){let{components:t,...n}=e;return(0,a.kt)(mn,(0,o.Z)({},dn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Number of samples optimized inside PPO together."))}un.isMDXComponent=!0;const cn={toc:[]},hn="wrapper";function kn(e){let{components:t,...n}=e;return(0,a.kt)(hn,(0,o.Z)({},cn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"This is the temperature that is used in the generate function during the PPO Rollout."))}kn.isMDXComponent=!0;const gn={toc:[]},fn="wrapper";function yn(e){let{components:t,...n}=e;return(0,a.kt)(fn,(0,o.Z)({},gn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"When enabled, this will offload the reward model weights to CPU when not in use. This can be useful when training on a GPU with limited memory. The weights will be moved back to the GPU when needed."))}yn.isMDXComponent=!0;const vn={toc:[]},bn="wrapper";function xn(e){let{components:t,...n}=e;return(0,a.kt)(bn,(0,o.Z)({},vn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the random probability of the input text tokens to be randomly masked during training. "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Increasing this setting can be helpful to avoid overfitting and apply regularization"),(0,a.kt)("li",{parentName:"ul"},"Each token is randomly replaced by a masking token based on the specified probability")))}xn.isMDXComponent=!0;const Tn={toc:[]},wn="wrapper";function Dn(e){let{components:t,...n}=e;return(0,a.kt)(wn,(0,o.Z)({},Tn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If ",(0,a.kt)("inlineCode",{parentName:"p"},"Parent Column")," is set, this random augmentation will skip parent concatenation during training at each parent with this specified probability."))}Dn.isMDXComponent=!0;const Mn={toc:[]},Ln="wrapper";function Nn(e){let{components:t,...n}=e;return(0,a.kt)(Ln,(0,o.Z)({},Mn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"While training, each sample will be concatenated to a random other sample simulating unrelated chained conversations. Can be specified without using a ",(0,a.kt)("inlineCode",{parentName:"p"},"Parent Column"),"."))}Nn.isMDXComponent=!0;const Sn={toc:[]},Xn="wrapper";function Cn(e){let{components:t,...n}=e;return(0,a.kt)(Xn,(0,o.Z)({},Sn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the metric to evaluate the model's performance. "),(0,a.kt)("p",null,"We provide several metric options for evaluating the performance of your model.\nIn addition to the BLEU and the Perplexity score, we offer GPT metrics that utilize the OpenAI API to determine whether\nthe predicted answer is more favorable than the ground truth answer.\nTo use these metrics, you can either export your OpenAI API key as an environment variable before starting LLM Studio,\nor you can specify it in the Settings Menu within the UI."))}Cn.isMDXComponent=!0;const On={toc:[]},Pn="wrapper";function Zn(e){let{components:t,...n}=e;return(0,a.kt)(Pn,(0,o.Z)({},On,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the min length value H2O LLM Studio uses for the generated text."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"This setting impacts the evaluation metrics and should depend on the dataset and average output sequence length that is expected to be predicted.")))}Zn.isMDXComponent=!0;const An={toc:[]},zn="wrapper";function En(e){let{components:t,...n}=e;return(0,a.kt)(zn,(0,o.Z)({},An,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the max length value H2O LLM Studio uses for the generated text."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Similar to the ",(0,a.kt)("strong",{parentName:"li"},"Max Length")," setting in the ",(0,a.kt)("em",{parentName:"li"},"tokenizer settings")," section, this setting specifies the maximum number of tokens to predict for a given prediction sample."),(0,a.kt)("li",{parentName:"ul"},"This setting impacts the evaluation metrics and should depend on the dataset and average output sequence length that is expected to be predicted.")))}En.isMDXComponent=!0;const Hn={toc:[]},In="wrapper";function Gn(e){let{components:t,...n}=e;return(0,a.kt)(In,(0,o.Z)({},Hn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the size of a mini-batch uses during an iteration of the inference. ",(0,a.kt)("strong",{parentName:"p"},"Batch size")," defines the batch size used per GPU."))}Gn.isMDXComponent=!0;const Rn={toc:[]},qn="wrapper";function Wn(e){let{components:t,...n}=e;return(0,a.kt)(qn,(0,o.Z)({},Rn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Determines whether to sample from the next token distribution instead of choosing the token with the highest probability. If turned ",(0,a.kt)("strong",{parentName:"p"},"On"),", the next token in a predicted sequence is sampled based on the probabilities. If turned ",(0,a.kt)("strong",{parentName:"p"},"Off"),", the highest probability is always chosen."))}Wn.isMDXComponent=!0;const Un={toc:[]},jn="wrapper";function Kn(e){let{components:t,...n}=e;return(0,a.kt)(jn,(0,o.Z)({},Un,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the number of beams to use for beam search. ",(0,a.kt)("em",{parentName:"p"},"Num Beams")," default value is 1  (a single beam); no beam search."),(0,a.kt)("p",null,"A higher ",(0,a.kt)("em",{parentName:"p"},"Num Beams")," value can increase prediction runtime while potentially improving accuracy."))}Kn.isMDXComponent=!0;const Bn={toc:[]},Fn="wrapper";function _n(e){let{components:t,...n}=e;return(0,a.kt)(Fn,(0,o.Z)({},Bn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the temperature to use for sampling from the next token distribution during validation and inference. In other words, the defined temperature controls the randomness of predictions by scaling the logits before applying ",(0,a.kt)("a",{href:"https://www.researchgate.net/figure/The-Gumbel-Softmax-distribution-interpolates-between-discrete-one-hot-encoded-categorical_fig4_309663606",target:"_blank"},"softmax"),". A higher temperature makes the distribution more random."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Modify the temperature value if you have the ",(0,a.kt)("strong",{parentName:"li"},"Do Sample")," setting enabled (",(0,a.kt)("strong",{parentName:"li"},"On"),")."),(0,a.kt)("li",{parentName:"ul"},"To learn more about this setting, refer to the following article: ",(0,a.kt)("a",{href:"https://huggingface.co/blog/how-to-generate",target:"_blank"},"How to generate text: using different decoding methods for language generation with Transformers"),".")))}_n.isMDXComponent=!0;const Vn={toc:[]},Yn="wrapper";function Qn(e){let{components:t,...n}=e;return(0,a.kt)(Yn,(0,o.Z)({},Vn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The parameter for repetition penalty. 1.0 means no penalty. See ",(0,a.kt)("a",{parentName:"p",href:"https://arxiv.org/pdf/1909.05858.pdf"},"https://arxiv.org/pdf/1909.05858.pdf")," for more details."))}Qn.isMDXComponent=!0;const Jn={toc:[]},$n="wrapper";function eo(e){let{components:t,...n}=e;return(0,a.kt)($n,(0,o.Z)({},Jn,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Will stop generation at occurrence of these additional tokens; multiple tokens should be split by comma ",(0,a.kt)("inlineCode",{parentName:"p"},","),"."))}eo.isMDXComponent=!0;const to={toc:[]},no="wrapper";function oo(e){let{components:t,...n}=e;return(0,a.kt)(no,(0,o.Z)({},to,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If > 0, only keep the top k tokens with the highest probability (top-k filtering)."))}oo.isMDXComponent=!0;const ao={toc:[]},io="wrapper";function ro(e){let{components:t,...n}=e;return(0,a.kt)(io,(0,o.Z)({},ao,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering)."))}ro.isMDXComponent=!0;const lo={toc:[]},so="wrapper";function po(e){let{components:t,...n}=e;return(0,a.kt)(so,(0,o.Z)({},lo,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Determines the list of GPUs H2O LLM Studio can use for the experiment. GPUs are listed by name, referring to their system ID (starting from 1)."))}po.isMDXComponent=!0;const mo={toc:[]},uo="wrapper";function co(e){let{components:t,...n}=e;return(0,a.kt)(uo,(0,o.Z)({},mo,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Determines whether to use mixed-precision. When turned ",(0,a.kt)("strong",{parentName:"p"},"Off"),", H2O LLM Studio does not use mixed-precision."),(0,a.kt)("p",null,"Mixed-precision is a technique that helps decrease memory consumption and increases training speed."))}co.isMDXComponent=!0;const ho={toc:[]},ko="wrapper";function go(e){let{components:t,...n}=e;return(0,a.kt)(ko,(0,o.Z)({},ho,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Compiles the model with Torch. Experimental!"))}go.isMDXComponent=!0;const fo={toc:[]},yo="wrapper";function vo(e){let{components:t,...n}=e;return(0,a.kt)(yo,(0,o.Z)({},fo,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Wraps the model with native Torch FSDP. Experimental!"))}vo.isMDXComponent=!0;const bo={toc:[]},xo="wrapper";function To(e){let{components:t,...n}=e;return(0,a.kt)(xo,(0,o.Z)({},bo,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"In Distributed Data Parallel (DDP) mode, ",(0,a.kt)("inlineCode",{parentName:"p"},"prepare_for_backward()")," is called at the end of DDP forward pass. It traverses the autograd graph to find unused parameters when ",(0,a.kt)("inlineCode",{parentName:"p"},"find_unused_parameters")," is set to True in DDP constructor."),(0,a.kt)("p",null,"Note that traversing the autograd graph introduces extra overheads, so applications should only set to True when necessary."))}To.isMDXComponent=!0;const wo={toc:[]},Do="wrapper";function Mo(e){let{components:t,...n}=e;return(0,a.kt)(Do,(0,o.Z)({},wo,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Trust remote code. This can be necessary for some models that use code which is not (yet) part of the ",(0,a.kt)("inlineCode",{parentName:"p"},"transformers")," package. Should always be checked with this option being switched ",(0,a.kt)("strong",{parentName:"p"},"Off")," first."))}Mo.isMDXComponent=!0;const Lo={toc:[]},No="wrapper";function So(e){let{components:t,...n}=e;return(0,a.kt)(No,(0,o.Z)({},Lo,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the number of workers H2O LLM Studio uses for the ",(0,a.kt)("em",{parentName:"p"},"DataLoader"),". In other words, it defines the number of CPU processes to use when reading and loading data to GPUs during model training."))}So.isMDXComponent=!0;const Xo={toc:[]},Co="wrapper";function Oo(e){let{components:t,...n}=e;return(0,a.kt)(Co,(0,o.Z)({},Xo,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the random seed value that H2O LLM Studio uses during model training. It defaults to -1, an arbitrary value. When the value is modified (not -1), the random seed allows results to be reproducible\u2014defining a seed aids in obtaining predictable and repeatable results every time. Otherwise, not modifying the default seed value (-1) leads to random numbers at every invocation."))}Oo.isMDXComponent=!0;const Po={toc:[]},Zo="wrapper";function Ao(e){let{components:t,...n}=e;return(0,a.kt)(Zo,(0,o.Z)({},Po,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines the logger type that H2O LLM Studio uses for model training"),(0,a.kt)("p",null,"Options"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"None"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio does not use any logger."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Neptune"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"H2O LLM Studio uses Neptune as a logger to track the experiment. To use Neptune, you must specify a ",(0,a.kt)("strong",{parentName:"li"},"Neptune API token")," and a ",(0,a.kt)("strong",{parentName:"li"},"Neptune project"),".")))))}Ao.isMDXComponent=!0;const zo={},Eo="Experiment settings",Ho={unversionedId:"guide/experiments/experiment-settings",id:"guide/experiments/experiment-settings",title:"Experiment settings",description:"The settings for creating an experiment are grouped into the following sections:",source:"@site/docs/guide/experiments/experiment-settings.md",sourceDirName:"guide/experiments",slug:"/guide/experiments/experiment-settings",permalink:"/h2o-llmstudio/guide/experiments/experiment-settings",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"defaultSidebar",previous:{title:"Merge datasets",permalink:"/h2o-llmstudio/guide/datasets/merge-datasets"},next:{title:"Create an experiment",permalink:"/h2o-llmstudio/guide/experiments/create-an-experiment"}},Io={},Go=[{value:"General settings",id:"general-settings",level:2},{value:"Dataset",id:"dataset",level:3},{value:"Problem type",id:"problem-type",level:3},{value:"Import config from YAML",id:"import-config-from-yaml",level:3},{value:"Experiment name",id:"experiment-name",level:3},{value:"LLM backbone",id:"llm-backbone",level:3},{value:"Dataset settings",id:"dataset-settings",level:2},{value:"Train dataframe",id:"train-dataframe",level:3},{value:"Validation strategy",id:"validation-strategy",level:3},{value:"Validation size",id:"validation-size",level:3},{value:"Data sample",id:"data-sample",level:3},{value:"Prompt column",id:"prompt-column",level:3},{value:"Answer column",id:"answer-column",level:3},{value:"Parent ID column",id:"parent-id-column",level:3},{value:"Text prompt start",id:"text-prompt-start",level:3},{value:"Text answer separator",id:"text-answer-separator",level:3},{value:"Adaptive Kl control",id:"adaptive-kl-control",level:2},{value:"Add EOS token to prompt",id:"add-eos-token-to-prompt",level:3},{value:"Add EOS token to answer",id:"add-eos-token-to-answer",level:3},{value:"Mask prompt labels",id:"mask-prompt-labels",level:3},{value:"Tokenizer settings",id:"tokenizer-settings",level:2},{value:"Max length prompt",id:"max-length-prompt",level:3},{value:"Max length answer",id:"max-length-answer",level:3},{value:"Max length",id:"max-length",level:3},{value:"Add prompt answer tokens",id:"add-prompt-answer-tokens",level:3},{value:"Padding quantile",id:"padding-quantile",level:3},{value:"Use fast",id:"use-fast",level:3},{value:"Architecture settings",id:"architecture-settings",level:2},{value:"Backbone Dtype",id:"backbone-dtype",level:3},{value:"Gradient Checkpointing",id:"gradient-checkpointing",level:3},{value:"Force Embedding Gradients",id:"force-embedding-gradients",level:3},{value:"Intermediate dropout",id:"intermediate-dropout",level:3},{value:"Pretrained weights",id:"pretrained-weights",level:3},{value:"Training settings",id:"training-settings",level:2},{value:"Optimizer",id:"optimizer",level:3},{value:"Learning rate",id:"learning-rate",level:3},{value:"Batch size",id:"batch-size",level:3},{value:"Epochs",id:"epochs",level:3},{value:"Schedule",id:"schedule",level:3},{value:"Warmup epochs",id:"warmup-epochs",level:3},{value:"Weight decay",id:"weight-decay",level:3},{value:"Gradient clip",id:"gradient-clip",level:3},{value:"Grad accumulation",id:"grad-accumulation",level:3},{value:"Lora",id:"lora",level:3},{value:"Lora R",id:"lora-r",level:3},{value:"Lora Alpha",id:"lora-alpha",level:3},{value:"Lora dropout",id:"lora-dropout",level:3},{value:"Lora target modules",id:"lora-target-modules",level:3},{value:"Save best checkpoint",id:"save-best-checkpoint",level:3},{value:"Evaluation epochs",id:"evaluation-epochs",level:3},{value:"Evaluate before training",id:"evaluate-before-training",level:3},{value:"Train validation data",id:"train-validation-data",level:3},{value:"Use RLHF",id:"use-rlhf",level:3},{value:"Reward model",id:"reward-model",level:3},{value:"Adaptive KL control",id:"adaptive-kl-control-1",level:3},{value:"Initial KL coefficient",id:"initial-kl-coefficient",level:3},{value:"KL target",id:"kl-target",level:3},{value:"KL Horizon",id:"kl-horizon",level:3},{value:"Advantages gamma",id:"advantages-gamma",level:3},{value:"Advantages Lambda",id:"advantages-lambda",level:3},{value:"PPO clip policy",id:"ppo-clip-policy",level:3},{value:"PPO clip value",id:"ppo-clip-value",level:3},{value:"Scaling factor value loss",id:"scaling-factor-value-loss",level:3},{value:"PPO epochs",id:"ppo-epochs",level:3},{value:"PPO Batch Size",id:"ppo-batch-size",level:3},{value:"PPO generate temperature",id:"ppo-generate-temperature",level:3},{value:"Offload reward model",id:"offload-reward-model",level:3},{value:"Augmentation settings",id:"augmentation-settings",level:2},{value:"Token mask probability",id:"token-mask-probability",level:3},{value:"Skip parent probability",id:"skip-parent-probability",level:3},{value:"Random parent probability",id:"random-parent-probability",level:3},{value:"Prediction settings",id:"prediction-settings",level:2},{value:"Metric",id:"metric",level:3},{value:"Min length inference",id:"min-length-inference",level:3},{value:"Max length inference",id:"max-length-inference",level:3},{value:"Batch size inference",id:"batch-size-inference",level:3},{value:"Do sample",id:"do-sample",level:3},{value:"Num beams",id:"num-beams",level:3},{value:"Temperature",id:"temperature",level:3},{value:"Repetition penalty",id:"repetition-penalty",level:3},{value:"Stop tokens",id:"stop-tokens",level:3},{value:"Top K",id:"top-k",level:3},{value:"Top P",id:"top-p",level:3},{value:"Environment settings",id:"environment-settings",level:2},{value:"GPUs",id:"gpus",level:3},{value:"Mixed precision",id:"mixed-precision",level:3},{value:"Compile model",id:"compile-model",level:3},{value:"Use FSDP",id:"use-fsdp",level:3},{value:"Find unused parameters",id:"find-unused-parameters",level:3},{value:"Trust remote code",id:"trust-remote-code",level:3},{value:"Number of workers",id:"number-of-workers",level:3},{value:"Seed",id:"seed",level:3},{value:"Logging settings",id:"logging-settings",level:2},{value:"Logger",id:"logger",level:3},{value:"Number of texts",id:"number-of-texts",level:3}],Ro=(qo="LSnumoftexts",function(e){return console.warn("Component "+qo+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var qo;const Wo={toc:Go},Uo="wrapper";function jo(e){let{components:t,...n}=e;return(0,a.kt)(Uo,(0,o.Z)({},Wo,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"experiment-settings"},"Experiment settings"),(0,a.kt)("p",null,"The settings for creating an experiment are grouped into the following sections: "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#general-settings"},"General settings")," "),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#dataset-settings"},"Dataset settings")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#tokenizer-settings"},"Tokenizer settings")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#architecture-settings"},"Architecture settings")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#training-settings"},"Training settings")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#augmentation-settings"},"Augmentation settings")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#prediction-settings"},"Prediction settings")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#environment-settings"},"Environment settings")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#logging-settings"},"Logging settings"))),(0,a.kt)("p",null,"The settings under each category are listed and described below."),(0,a.kt)("h2",{id:"general-settings"},"General settings"),(0,a.kt)("h3",{id:"dataset"},"Dataset"),(0,a.kt)(l,{mdxType:"GeneralSettingsDataset"}),(0,a.kt)("h3",{id:"problem-type"},"Problem type"),(0,a.kt)(d,{mdxType:"GeneralSettingsProblemType"}),(0,a.kt)("h3",{id:"import-config-from-yaml"},"Import config from YAML"),(0,a.kt)(c,{mdxType:"GSImportConfigFromYaml"}),(0,a.kt)("h3",{id:"experiment-name"},"Experiment name"),(0,a.kt)(g,{mdxType:"GSExperimentName"}),(0,a.kt)("h3",{id:"llm-backbone"},"LLM backbone"),(0,a.kt)(v,{mdxType:"GSLLMBackbone"}),(0,a.kt)("h2",{id:"dataset-settings"},"Dataset settings"),(0,a.kt)("h3",{id:"train-dataframe"},"Train dataframe"),(0,a.kt)(b.ZP,{mdxType:"DSTrainDataframe"}),(0,a.kt)("h3",{id:"validation-strategy"},"Validation strategy"),(0,a.kt)(w,{mdxType:"DSvalidationStrategy"}),(0,a.kt)("h3",{id:"validation-size"},"Validation size"),(0,a.kt)(L,{mdxType:"DSvalidationSize"}),(0,a.kt)("h3",{id:"data-sample"},"Data sample"),(0,a.kt)(X,{mdxType:"DSdataSample"}),(0,a.kt)("h3",{id:"prompt-column"},"Prompt column"),(0,a.kt)(C.ZP,{mdxType:"DSpromptColumn"}),(0,a.kt)("h3",{id:"answer-column"},"Answer column"),(0,a.kt)(O.ZP,{mdxType:"DSanswerColumn"}),(0,a.kt)("h3",{id:"parent-id-column"},"Parent ID column"),(0,a.kt)(P.ZP,{mdxType:"DSparentIdColumn"}),(0,a.kt)("h3",{id:"text-prompt-start"},"Text prompt start"),(0,a.kt)(z,{mdxType:"DStextPromptStart"}),(0,a.kt)("h3",{id:"text-answer-separator"},"Text answer separator"),(0,a.kt)(I,{mdxType:"DStextAnswerSeparator"}),(0,a.kt)("h2",{id:"adaptive-kl-control"},"Adaptive Kl control"),(0,a.kt)(q,{mdxType:"DSadaptiveKlControl"}),(0,a.kt)("h3",{id:"add-eos-token-to-prompt"},"Add EOS token to prompt"),(0,a.kt)(j,{mdxType:"DSaddEosTokentoprompt"}),(0,a.kt)("h3",{id:"add-eos-token-to-answer"},"Add EOS token to answer"),(0,a.kt)(F,{mdxType:"DSaddEosTokentoanswer"}),(0,a.kt)("h3",{id:"mask-prompt-labels"},"Mask prompt labels"),(0,a.kt)(Y,{mdxType:"DSmaskPromptlabels"}),(0,a.kt)("h2",{id:"tokenizer-settings"},"Tokenizer settings"),(0,a.kt)("h3",{id:"max-length-prompt"},"Max length prompt"),(0,a.kt)($,{mdxType:"TSmaxLengthPrompt"}),(0,a.kt)("h3",{id:"max-length-answer"},"Max length answer"),(0,a.kt)(ne,{mdxType:"TSmaxLengthAnswer"}),(0,a.kt)("h3",{id:"max-length"},"Max length"),(0,a.kt)(ie,{mdxType:"TSmaxLength"}),(0,a.kt)("h3",{id:"add-prompt-answer-tokens"},"Add prompt answer tokens"),(0,a.kt)(se,{mdxType:"TSaddpromptanswertokens"}),(0,a.kt)("h3",{id:"padding-quantile"},"Padding quantile"),(0,a.kt)(me,{mdxType:"TSpaddingQuantile"}),(0,a.kt)("h3",{id:"use-fast"},"Use fast"),(0,a.kt)(he,{mdxType:"TSuseFast"}),(0,a.kt)("h2",{id:"architecture-settings"},"Architecture settings"),(0,a.kt)("h3",{id:"backbone-dtype"},"Backbone Dtype"),(0,a.kt)(fe,{mdxType:"ASBackboneDtype"}),(0,a.kt)("h3",{id:"gradient-checkpointing"},"Gradient Checkpointing"),(0,a.kt)(be,{mdxType:"ASGradientcheckpointing"}),(0,a.kt)("h3",{id:"force-embedding-gradients"},"Force Embedding Gradients"),(0,a.kt)(we,{mdxType:"ASforceEmbeddingGradients"}),(0,a.kt)("h3",{id:"intermediate-dropout"},"Intermediate dropout"),(0,a.kt)(Le,{mdxType:"ASintermediateDropout"}),(0,a.kt)("h3",{id:"pretrained-weights"},"Pretrained weights"),(0,a.kt)(Xe,{mdxType:"ASpretrainedWeights"}),(0,a.kt)("h2",{id:"training-settings"},"Training settings"),(0,a.kt)("h3",{id:"optimizer"},"Optimizer"),(0,a.kt)(Pe,{mdxType:"TSoptimizer"}),(0,a.kt)("h3",{id:"learning-rate"},"Learning rate"),(0,a.kt)(ze,{mdxType:"TSlearningRate"}),(0,a.kt)("h3",{id:"batch-size"},"Batch size"),(0,a.kt)(Ie,{mdxType:"TSbatchSize"}),(0,a.kt)("h3",{id:"epochs"},"Epochs"),(0,a.kt)(qe,{mdxType:"TSepochs"}),(0,a.kt)("h3",{id:"schedule"},"Schedule"),(0,a.kt)(je,{mdxType:"TSschedule"}),(0,a.kt)("h3",{id:"warmup-epochs"},"Warmup epochs"),(0,a.kt)(Fe,{mdxType:"TSwarmupEpochs"}),(0,a.kt)("h3",{id:"weight-decay"},"Weight decay"),(0,a.kt)(Ye,{mdxType:"TSweightDecay"}),(0,a.kt)("h3",{id:"gradient-clip"},"Gradient clip"),(0,a.kt)($e,{mdxType:"TSGradientclip"}),(0,a.kt)("h3",{id:"grad-accumulation"},"Grad accumulation"),(0,a.kt)(nt,{mdxType:"TSgradAccumulation"}),(0,a.kt)("h3",{id:"lora"},"Lora"),(0,a.kt)(it,{mdxType:"TSlora"}),(0,a.kt)("h3",{id:"lora-r"},"Lora R"),(0,a.kt)(st,{mdxType:"TSloraR"}),(0,a.kt)("h3",{id:"lora-alpha"},"Lora Alpha"),(0,a.kt)(mt,{mdxType:"TSloraAlpha"}),(0,a.kt)("h3",{id:"lora-dropout"},"Lora dropout"),(0,a.kt)(ht,{mdxType:"TSloraDropout"}),(0,a.kt)("h3",{id:"lora-target-modules"},"Lora target modules"),(0,a.kt)(ft,{mdxType:"TSloraTargetModules"}),(0,a.kt)("h3",{id:"save-best-checkpoint"},"Save best checkpoint"),(0,a.kt)(bt,{mdxType:"TSsavebestcheckpoint"}),(0,a.kt)("h3",{id:"evaluation-epochs"},"Evaluation epochs"),(0,a.kt)(wt,{mdxType:"TSevaluationepochs"}),(0,a.kt)("h3",{id:"evaluate-before-training"},"Evaluate before training"),(0,a.kt)(Lt,{mdxType:"TSevaluationbeforetraining"}),(0,a.kt)("h3",{id:"train-validation-data"},"Train validation data"),(0,a.kt)(Xt,{mdxType:"TStrainvalidationdata"}),(0,a.kt)("h3",{id:"use-rlhf"},"Use RLHF"),(0,a.kt)(Pt,{mdxType:"TSuseRHLF"}),(0,a.kt)("h3",{id:"reward-model"},"Reward model"),(0,a.kt)(zt,{mdxType:"TSrewardModel"}),(0,a.kt)("h3",{id:"adaptive-kl-control-1"},"Adaptive KL control"),(0,a.kt)(q,{mdxType:"DSadaptiveKlControl"}),(0,a.kt)("h3",{id:"initial-kl-coefficient"},"Initial KL coefficient"),(0,a.kt)(It,{mdxType:"TSinitialKlCoefficient"}),(0,a.kt)("h3",{id:"kl-target"},"KL target"),(0,a.kt)(qt,{mdxType:"TSklTarget"}),(0,a.kt)("h3",{id:"kl-horizon"},"KL Horizon"),(0,a.kt)(jt,{mdxType:"TSklHorizon"}),(0,a.kt)("h3",{id:"advantages-gamma"},"Advantages gamma"),(0,a.kt)(Ft,{mdxType:"TSadvantagesGamma"}),(0,a.kt)("h3",{id:"advantages-lambda"},"Advantages Lambda"),(0,a.kt)(Yt,{mdxType:"TSadvantagesLambda"}),(0,a.kt)("h3",{id:"ppo-clip-policy"},"PPO clip policy"),(0,a.kt)($t,{mdxType:"TSppoClipPolicy"}),(0,a.kt)("h3",{id:"ppo-clip-value"},"PPO clip value"),(0,a.kt)(nn,{mdxType:"TSppoClipValue"}),(0,a.kt)("h3",{id:"scaling-factor-value-loss"},"Scaling factor value loss"),(0,a.kt)(rn,{mdxType:"TSscalingFactorValueLoss"}),(0,a.kt)("h3",{id:"ppo-epochs"},"PPO epochs"),(0,a.kt)(pn,{mdxType:"TSppoEpochs"}),(0,a.kt)("h3",{id:"ppo-batch-size"},"PPO Batch Size"),(0,a.kt)(un,{mdxType:"TSppoBatchSize"}),(0,a.kt)("h3",{id:"ppo-generate-temperature"},"PPO generate temperature"),(0,a.kt)(kn,{mdxType:"TSppoGenerateTemp"}),(0,a.kt)("h3",{id:"offload-reward-model"},"Offload reward model"),(0,a.kt)(yn,{mdxType:"TSoffloadRewardModel"}),(0,a.kt)("h2",{id:"augmentation-settings"},"Augmentation settings"),(0,a.kt)("h3",{id:"token-mask-probability"},"Token mask probability"),(0,a.kt)(xn,{mdxType:"AStokenmaskprobability"}),(0,a.kt)("h3",{id:"skip-parent-probability"},"Skip parent probability"),(0,a.kt)(Dn,{mdxType:"ASskipParentprobability"}),(0,a.kt)("h3",{id:"random-parent-probability"},"Random parent probability"),(0,a.kt)(Nn,{mdxType:"ASrandomparentprobability"}),(0,a.kt)("h2",{id:"prediction-settings"},"Prediction settings"),(0,a.kt)("h3",{id:"metric"},"Metric"),(0,a.kt)(Cn,{mdxType:"PSmetric"}),(0,a.kt)("h3",{id:"min-length-inference"},"Min length inference"),(0,a.kt)(Zn,{mdxType:"PSminlengthinference"}),(0,a.kt)("h3",{id:"max-length-inference"},"Max length inference"),(0,a.kt)(En,{mdxType:"PSmaxlengthinference"}),(0,a.kt)("h3",{id:"batch-size-inference"},"Batch size inference"),(0,a.kt)(Gn,{mdxType:"PSbatchsizeinference"}),(0,a.kt)("h3",{id:"do-sample"},"Do sample"),(0,a.kt)(Wn,{mdxType:"PSdosample"}),(0,a.kt)("h3",{id:"num-beams"},"Num beams"),(0,a.kt)(Kn,{mdxType:"PSnumbeams"}),(0,a.kt)("h3",{id:"temperature"},"Temperature"),(0,a.kt)(_n,{mdxType:"PStemperature"}),(0,a.kt)("h3",{id:"repetition-penalty"},"Repetition penalty"),(0,a.kt)(Qn,{mdxType:"PSrepetitionpenalty"}),(0,a.kt)("h3",{id:"stop-tokens"},"Stop tokens"),(0,a.kt)(eo,{mdxType:"PSstoptokens"}),(0,a.kt)("h3",{id:"top-k"},"Top K"),(0,a.kt)(oo,{mdxType:"PStopk"}),(0,a.kt)("h3",{id:"top-p"},"Top P"),(0,a.kt)(ro,{mdxType:"PStopp"}),(0,a.kt)("h2",{id:"environment-settings"},"Environment settings"),(0,a.kt)("h3",{id:"gpus"},"GPUs"),(0,a.kt)(po,{mdxType:"ESgpus"}),(0,a.kt)("h3",{id:"mixed-precision"},"Mixed precision"),(0,a.kt)(co,{mdxType:"ESmixedprecision"}),(0,a.kt)("h3",{id:"compile-model"},"Compile model"),(0,a.kt)(go,{mdxType:"EScompilemodel"}),(0,a.kt)("h3",{id:"use-fsdp"},"Use FSDP"),(0,a.kt)(vo,{mdxType:"ESusefsdp"}),(0,a.kt)("h3",{id:"find-unused-parameters"},"Find unused parameters"),(0,a.kt)(To,{mdxType:"ESfindunusedparameters"}),(0,a.kt)("h3",{id:"trust-remote-code"},"Trust remote code"),(0,a.kt)(Mo,{mdxType:"EStrustremotecode"}),(0,a.kt)("h3",{id:"number-of-workers"},"Number of workers"),(0,a.kt)(So,{mdxType:"ESnumofworkers"}),(0,a.kt)("h3",{id:"seed"},"Seed"),(0,a.kt)(Oo,{mdxType:"ESseed"}),(0,a.kt)("h2",{id:"logging-settings"},"Logging settings"),(0,a.kt)("h3",{id:"logger"},"Logger"),(0,a.kt)(Ao,{mdxType:"LSlogger"}),(0,a.kt)("h3",{id:"number-of-texts"},"Number of texts"),(0,a.kt)(Ro,{mdxType:"LSnumoftexts"}))}jo.isMDXComponent=!0},4396:(e,t,n)=>{n.d(t,{ZP:()=>l});var o=n(7462),a=(n(7294),n(3905));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.kt)(r,(0,o.Z)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The column in the dataset containing the expected output."))}l.isMDXComponent=!0},5661:(e,t,n)=>{n.d(t,{ZP:()=>l});var o=n(7462),a=(n(7294),n(3905));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.kt)(r,(0,o.Z)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"An optional column specifying the parent id to be used for chained conversations. The value of this column needs to match an additional column with the name ",(0,a.kt)("inlineCode",{parentName:"p"},"id"),". If provided, the prompt will be concatenated after preceeding parent rows."))}l.isMDXComponent=!0},8973:(e,t,n)=>{n.d(t,{ZP:()=>l});var o=n(7462),a=(n(7294),n(3905));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.kt)(r,(0,o.Z)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The column in the dataset containing the user prompt."))}l.isMDXComponent=!0},1953:(e,t,n)=>{n.d(t,{ZP:()=>l});var o=n(7462),a=(n(7294),n(3905));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.kt)(r,(0,o.Z)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Defines a ",(0,a.kt)("inlineCode",{parentName:"p"},".csv")," or ",(0,a.kt)("inlineCode",{parentName:"p"},".pq")," file containing a dataframe with training records that H2O LLM Studio uses to ",(0,a.kt)("em",{parentName:"p"},"train")," the model."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The records are combined into mini-batches when training the model.")))}l.isMDXComponent=!0}}]);