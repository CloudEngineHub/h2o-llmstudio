"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[675],{5680:(e,n,t)=>{t.d(n,{xA:()=>c,yg:()=>m});var r=t(6540);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=r.createContext({}),d=function(e){var n=r.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},c=function(e){var n=d(e.components);return r.createElement(l.Provider,{value:n},e.children)},g="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},p=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),g=d(t),p=a,m=g["".concat(l,".").concat(p)]||g[p]||u[p]||i;return t?r.createElement(m,o(o({ref:n},c),{},{components:t})):r.createElement(m,o({ref:n},c))}));function m(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=t.length,o=new Array(i);o[0]=p;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[g]="string"==typeof e?e:a,o[1]=s;for(var d=2;d<i;d++)o[d]=t[d];return r.createElement.apply(null,o)}return r.createElement.apply(null,t)}p.displayName="MDXCreateElement"},5131:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>d});var r=t(8168),a=(t(6540),t(5680));const i={},o="Key terms",s={unversionedId:"key-terms",id:"key-terms",title:"Key terms",description:"H2O LLM Studio uses several key terms across its documentation, and each, in turn, is explained in the sections below.",source:"@site/docs/key-terms.md",sourceDirName:".",slug:"/key-terms",permalink:"/h2o-llmstudio/key-terms",draft:!1,tags:[],version:"current",frontMatter:{}},l={},d=[{value:"Prompt Engineering",id:"prompt-engineering",level:2},{value:"Agents",id:"agents",level:2},{value:"ELO",id:"elo",level:2},{value:"Vector Store",id:"vector-store",level:2},{value:"Pre-training",id:"pre-training",level:2},{value:"Attention",id:"attention",level:2},{value:"Embedding",id:"embedding",level:2},{value:"Language Model",id:"language-model",level:2},{value:"Transformer",id:"transformer",level:2},{value:"Encoders and Decoders",id:"encoders-and-decoders",level:2},{value:"Text generation",id:"text-generation",level:2},{value:"In-context learning",id:"in-context-learning",level:2},{value:"Few-shot learning",id:"few-shot-learning",level:2},{value:"Summarization",id:"summarization",level:2},{value:"Fine-tuning",id:"fine-tuning",level:2},{value:"GPT",id:"gpt",level:2}],c={toc:d},g="wrapper";function u(e){let{components:n,...t}=e;return(0,a.yg)(g,(0,r.A)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"key-terms"},"Key terms"),(0,a.yg)("p",null,"H2O LLM Studio uses several key terms across its documentation, and each, in turn, is explained in the sections below."),(0,a.yg)("h2",{id:"prompt-engineering"},"Prompt Engineering"),(0,a.yg)("p",null,"Prompt engineering involves crafting precise and effective input queries to guide language models in generating desired outputs or responses."),(0,a.yg)("h2",{id:"agents"},"Agents"),(0,a.yg)("p",null,"Software entities or components that interact with data or perform tasks within a system."),(0,a.yg)("h2",{id:"elo"},"ELO"),(0,a.yg)("p",null,"An algorithm or method used to assess and rank the performance or accuracy of language models based on their proficiency in understanding and processing textual data."),(0,a.yg)("h2",{id:"vector-store"},"Vector Store"),(0,a.yg)("p",null,"A Vector Store stores numerical representations of text for fast access in language models."),(0,a.yg)("h2",{id:"pre-training"},"Pre-training"),(0,a.yg)("p",null,"The initial phase of training a machine learning model on a large dataset to learn general features before fine-tuning on a specific task."),(0,a.yg)("h2",{id:"attention"},"Attention"),(0,a.yg)("p",null,"A mechanism that enables models to focus on specific parts of input data relevant to the task at hand, enhancing their understanding and performance."),(0,a.yg)("h2",{id:"embedding"},"Embedding"),(0,a.yg)("p",null,"Embedding refers to a mathematical representation of words or tokens in a numerical vector space, enabling machine learning models to understand and process language based on their context and relationships."),(0,a.yg)("h2",{id:"language-model"},"Language Model"),(0,a.yg)("p",null,"A language model is an AI system that understands and generates human language, predicting and generating text based on patterns and context within a given sequence of words."),(0,a.yg)("h2",{id:"transformer"},"Transformer"),(0,a.yg)("p",null,"A Transformer refers to a neural network architecture specifically designed for processing sequential data like text, using attention mechanisms to learn contextual relationships between words or tokens."),(0,a.yg)("h2",{id:"encoders-and-decoders"},"Encoders and Decoders"),(0,a.yg)("p",null,"Encoders and decoders are vital parts of sequence-to-sequence models used in natural language processing. Encoders process input data into a fixed-size representation, while decoders generate an output sequence based on that representation."),(0,a.yg)("h2",{id:"text-generation"},"Text generation"),(0,a.yg)("p",null,"Text generation is the process of creating written content, such as sentences or paragraphs, using machine learning or AI algorithms based on patterns learned from existing text data."),(0,a.yg)("h2",{id:"in-context-learning"},"In-context learning"),(0,a.yg)("p",null,"In-context learning refers to the process where a machine learning model continuously improves and adapts by considering the context of new information within its existing knowledge, enhancing its accuracy and understanding over time."),(0,a.yg)("h2",{id:"few-shot-learning"},"Few-shot learning"),(0,a.yg)("p",null,"Few-shot learning refers to a machine learning technique where a model can learn from a very small amount of labeled data to generalize and make predictions accurately on new, unseen data."),(0,a.yg)("h2",{id:"summarization"},"Summarization"),(0,a.yg)("p",null,"Summarization is the process of condensing a larger piece of text into a shorter, coherent version while retaining its essential information."),(0,a.yg)("h2",{id:"fine-tuning"},"Fine-tuning"),(0,a.yg)("p",null,"Fine-tuning refers to adjusting and optimizing a pre-trained machine learning model using specific data to enhance its performance for a particular task."),(0,a.yg)("h2",{id:"gpt"},"GPT"),(0,a.yg)("p",null,'GPT stands for "Generative Pre-trained Transformer," a type of language model that uses transformers to understand and generate human-like text based on vast amounts of training data.'),(0,a.yg)("h1",{id:"gpu-deployment"},"GPU deployment"),(0,a.yg)("p",null,"GPU deployment is the utilization of graphics processing units (GPUs) to execute and accelerate the computations involved in deploying machine learning models, improving speed and efficiency in model inference or training."),(0,a.yg)("h1",{id:"tokenization"},"Tokenization"),(0,a.yg)("p",null,"Tokenization is the process of breaking text into smaller units, typically words or phrases, to analyze or process them individually within a natural language processing system."))}u.isMDXComponent=!0}}]);