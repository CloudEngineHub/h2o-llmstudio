"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[178],{5680:(e,t,n)=>{n.d(t,{xA:()=>g,yg:()=>c});var a=n(6540);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},g=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,g=l(e,["components","mdxType","originalType","parentName"]),u=p(n),m=o,c=u["".concat(s,".").concat(m)]||u[m]||d[m]||i;return n?a.createElement(c,r(r({ref:t},g),{},{components:n})):a.createElement(c,r({ref:t},g))}));function c(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:o,r[1]=l;for(var p=2;p<i;p++)r[p]=n[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},8205:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>ro,contentTitle:()=>oo,default:()=>go,frontMatter:()=>ao,metadata:()=>io,toc:()=>lo});var a=n(8168),o=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,o.yg)(r,(0,a.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Select the dataset for the experiment."))}l.isMDXComponent=!0;var s=n(2073);const p={toc:[]},g="wrapper";function u(e){let{components:t,...n}=e;return(0,o.yg)(g,(0,a.A)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the ",(0,o.yg)("inlineCode",{parentName:"p"},".yml")," file that defines the experiment settings. "),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio supports a ",(0,o.yg)("inlineCode",{parentName:"li"},".yml")," file import and export functionality. You can download the config settings of finished experiments, make changes, and re-upload them when starting a new experiment in any instance of H2O LLM Studio.")))}u.isMDXComponent=!0;const d={toc:[]},m="wrapper";function c(e){let{components:t,...n}=e;return(0,o.yg)(m,(0,a.A)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"It defines the name of the experiment."))}c.isMDXComponent=!0;const y={toc:[]},h="wrapper";function f(e){let{components:t,...n}=e;return(0,o.yg)(h,(0,a.A)({},y,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The ",(0,o.yg)("strong",{parentName:"p"},"LLM Backbone")," option is the most important setting as it sets the pretrained model weights."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Usually, it is good to use smaller architectures for quicker experiments and larger models when aiming for the highest accuracy"),(0,o.yg)("li",{parentName:"ul"},"If possible, leverage backbones pre-trained closely to your use case"),(0,o.yg)("li",{parentName:"ul"},"Any huggingface model can be used here (not limited to the ones in the dropdown list)")))}f.isMDXComponent=!0;var v=n(3385);const b={toc:[]},T="wrapper";function x(e){let{components:t,...n}=e;return(0,o.yg)(T,(0,a.A)({},b,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Specifies the validation strategy H2O LLM Studio uses for the experiment."),(0,o.yg)("p",null,"To properly assess the performance of your trained models, it is common practice to evaluate it on separate holdout data that the model has not seen during training. H2O LLM Studio allows you to specify different strategies for this task fitting your needs."),(0,o.yg)("p",null,"Options"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Custom holdout validation"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"Specifies a separate holdout dataframe."))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Automatic holdout validation"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"Allows to specify a holdout validation sample size that is automatically generated.")))))}x.isMDXComponent=!0;const w={toc:[]},D="wrapper";function M(e){let{components:t,...n}=e;return(0,o.yg)(D,(0,a.A)({},w,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines an optional relative size of the holdout validation set. H2O LLM Studio do automatically sample the selected\npercentage from the full training data, and build a holdout dataset that the model is validated on."))}M.isMDXComponent=!0;const L={toc:[]},N="wrapper";function A(e){let{components:t,...n}=e;return(0,o.yg)(N,(0,a.A)({},L,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the percentage of the data to use for the experiment. The default percentage is 100% (1)."),(0,o.yg)("p",null,"Changing the default value can significantly increase the training speed. Still, it might lead to a substantially poor accuracy value. Using 100% (1) of the data for final models is highly recommended."))}A.isMDXComponent=!0;var S=n(5886),X=n(8017),k=n(5690),C=n(5482);const O={toc:[]},P="wrapper";function z(e){let{components:t,...n}=e;return(0,o.yg)(P,(0,a.A)({},O,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Optional text to prepend to each prompt."))}z.isMDXComponent=!0;const H={toc:[]},E="wrapper";function I(e){let{components:t,...n}=e;return(0,o.yg)(E,(0,a.A)({},H,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Optional text to append to each prompt / prepend to each answer."))}I.isMDXComponent=!0;const G={toc:[]},R="wrapper";function U(e){let{components:t,...n}=e;return(0,o.yg)(R,(0,a.A)({},G,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Use adaptive KL control, otherwise linear."))}U.isMDXComponent=!0;const q={toc:[]},j="wrapper";function W(e){let{components:t,...n}=e;return(0,o.yg)(j,(0,a.A)({},q,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Adds EOS token at end of prompt."))}W.isMDXComponent=!0;const F={toc:[]},B="wrapper";function K(e){let{components:t,...n}=e;return(0,o.yg)(B,(0,a.A)({},F,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Adds EOS token at end of answer."))}K.isMDXComponent=!0;const _={toc:[]},V="wrapper";function Y(e){let{components:t,...n}=e;return(0,o.yg)(V,(0,a.A)({},_,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Whether to mask the prompt labels during training and only train on the loss of the answer."))}Y.isMDXComponent=!0;const Q={toc:[]},J="wrapper";function Z(e){let{components:t,...n}=e;return(0,o.yg)(J,(0,a.A)({},Q,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The maximum sequence length of the prompt to use during training. In case of chained samples, this max length refers to a single prompt length in the chain."))}Z.isMDXComponent=!0;const $={toc:[]},ee="wrapper";function te(e){let{components:t,...n}=e;return(0,o.yg)(ee,(0,a.A)({},$,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The maximum sequence length of the answer to use during training. In case of chained samples, this max length refers to a single answer length in the chain."))}te.isMDXComponent=!0;const ne={toc:[]},ae="wrapper";function oe(e){let{components:t,...n}=e;return(0,o.yg)(ae,(0,a.A)({},ne,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the maximum length of the input sequence H2O LLM Studio uses during model training. In other words, this setting specifies the maximum number of tokens an input text is transformed for model training."),(0,o.yg)("p",null,"A higher token count leads to higher memory usage that slows down training while increasing the probability of obtaining a higher accuracy value."),(0,o.yg)("p",null,"In case of Causal Language Modeling, this includes both prompt and answer, or all prompts and answers in case of chained samples. "),(0,o.yg)("p",null,"In Sequence to Sequence Modeling, this refers to the length of the prompt, or the length of a full chained sample."))}oe.isMDXComponent=!0;const ie={toc:[]},re="wrapper";function le(e){let{components:t,...n}=e;return(0,o.yg)(re,(0,a.A)({},ie,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Adds system, prompt and answer tokens as new tokens to the tokenizer. It is recommended to also set ",(0,o.yg)("inlineCode",{parentName:"p"},"Force Embedding Gradients")," in this case."))}le.isMDXComponent=!0;const se={toc:[]},pe="wrapper";function ge(e){let{components:t,...n}=e;return(0,o.yg)(pe,(0,a.A)({},se,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the padding quantile H2O LLM Studio uses to select the maximum token length per batch. H2O LLM Studio performs padding of shorter sequences up to the specified padding quantile instead of the selected ",(0,o.yg)("strong",{parentName:"p"},"Max length"),". H2O LLM Studio truncates longer sequences."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Lowering the quantile can significantly increase training runtime and reduce memory usage in unevenly distributed sequence lengths but can hurt performance "),(0,o.yg)("li",{parentName:"ul"},"The setting depends on the batch size and should be adjusted accordingly "),(0,o.yg)("li",{parentName:"ul"},"No padding is done in inference, and the selected ",(0,o.yg)("strong",{parentName:"li"},"Max Length")," is guaranteed"),(0,o.yg)("li",{parentName:"ul"},"Setting to 0 disables padding"),(0,o.yg)("li",{parentName:"ul"},"In case of distributed training, the quantile will be calculated across all GPUs")))}ge.isMDXComponent=!0;const ue={toc:[]},de="wrapper";function me(e){let{components:t,...n}=e;return(0,o.yg)(de,(0,a.A)({},ue,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The datatype of the weights in the LLM backbone."))}me.isMDXComponent=!0;const ce={toc:[]},ye="wrapper";function he(e){let{components:t,...n}=e;return(0,o.yg)(ye,(0,a.A)({},ce,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Determines whether H2O LLM Studio activates gradient checkpointing (GC) when training the model. Starting GC reduces the video random access memory (VRAM) footprint at the cost of a longer runtime (an additional forward pass). Turning ",(0,o.yg)("strong",{parentName:"p"},"On")," GC enables it during the training process."),(0,o.yg)("p",null,(0,o.yg)("strong",{parentName:"p"},"Caution"),"\nGradient checkpointing is an experimental setting that is not compatible with all backbones or all other settings."),(0,o.yg)("p",null,"Activating ",(0,o.yg)("em",{parentName:"p"},"GC")," comes at the cost of a longer training time; for that reason, try training without ",(0,o.yg)("em",{parentName:"p"},"GC")," first and only activate when experiencing ",(0,o.yg)("em",{parentName:"p"},"GPU out-of-memory (OOM)")," errors."))}he.isMDXComponent=!0;const fe={toc:[]},ve="wrapper";function be(e){let{components:t,...n}=e;return(0,o.yg)(ve,(0,a.A)({},fe,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the custom dropout rate H2O LLM Studio uses for intermediate layers in the transformer model."))}be.isMDXComponent=!0;const Te={toc:[]},xe="wrapper";function we(e){let{components:t,...n}=e;return(0,o.yg)(xe,(0,a.A)({},Te,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Allows you to specify a local path to the pretrained weights."))}we.isMDXComponent=!0;const De={toc:[]},Me="wrapper";function Le(e){let{components:t,...n}=e;return(0,o.yg)(Me,(0,a.A)({},De,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the algorithm or method (optimizer) to use for model training. The selected algorithm or method defines how the model should change the attributes of the neural network, such as weights and learning rate. Optimizers solve optimization problems and make more accurate updates to attributes to reduce learning losses."),(0,o.yg)("p",null,"Options:"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Adadelta"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"To learn about Adadelta, see ",(0,o.yg)("a",{href:"https://arxiv.org/abs/1212.5701",target:"_blank"},"ADADELTA: An Adaptive Learning Rate Method"),". "))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Adam"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"To learn about Adam, see ",(0,o.yg)("a",{href:"https://arxiv.org/abs/1412.6980",target:"_blank"},"Adam: A Method for Stochastic Optimization"),". "))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"AdamW"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"To learn about AdamW, see ",(0,o.yg)("a",{href:"https://arxiv.org/abs/1711.05101",target:"_blank"},"Decoupled Weight Decay Regularization"),"."))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"AdamW8bit"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"To learn about AdamW, see ",(0,o.yg)("a",{href:"https://arxiv.org/abs/1711.05101",target:"_blank"},"Decoupled Weight Decay Regularization"),"."))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"RMSprop")," ",(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"To learn about RMSprop, see ",(0,o.yg)("a",{href:"https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf",target:"_blank"},"Neural Networks for Machine Learning"),"."))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"SGD")," ",(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio uses a stochastic gradient descent optimizer.")))))}Le.isMDXComponent=!0;const Ne={toc:[]},Ae="wrapper";function Se(e){let{components:t,...n}=e;return(0,o.yg)(Ae,(0,a.A)({},Ne,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the loss function H2O LLM Studio utilizes during model training. The loss function is a differentiable function measuring the prediction error. The model utilizes gradients of the loss function to update the model weights during training. The options depend on the selected Problem Type."))}Se.isMDXComponent=!0;const Xe={toc:[]},ke="wrapper";function Ce(e){let{components:t,...n}=e;return(0,o.yg)(ke,(0,a.A)({},Xe,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the learning rate H2O LLM Studio uses when training the model, specifically when updating the neural network's weights. The learning rate is the speed at which the model updates its weights after processing each mini-batch of data."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Learning rate is an important setting to tune as it balances under- and overfitting."),(0,o.yg)("li",{parentName:"ul"},"The number of epochs highly impacts the optimal value of the learning rate.")))}Ce.isMDXComponent=!0;const Oe={toc:[]},Pe="wrapper";function ze(e){let{components:t,...n}=e;return(0,o.yg)(Pe,(0,a.A)({},Oe,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the learning rate to apply to certain layers of a model. H2O LLM Studio applies the regular learning rate to layers without a specified learning rate."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Backbone"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio applies a different learning rate to a body of the neural network architecture. "))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Value Head"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio applies a different learning rate to a value head of the neural network architecture. ")))),(0,o.yg)("p",null,"A common strategy is to apply a lower learning rate to the backbone of a model for better convergence and training stability."))}ze.isMDXComponent=!0;const He={toc:[]},Ee="wrapper";function Ie(e){let{components:t,...n}=e;return(0,o.yg)(Ee,(0,a.A)({},He,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"An optional list of layers to freeze during training. Full layer names will be matched against selected substrings. Only available without LoRA training."))}Ie.isMDXComponent=!0;const Ge={toc:[]},Re="wrapper";function Ue(e){let{components:t,...n}=e;return(0,o.yg)(Re,(0,a.A)({},Ge,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"If enabled, Flash Attention 2 will be used to compute the attention. Otherwise, the attention will be computed using the standard attention mechanism. "),(0,o.yg)("p",null,"Flash Attention 2 is a new attention mechanism that is faster and more memory efficient than the standard attention mechanism. Only newer GPUs support this feature."),(0,o.yg)("p",null,"See ",(0,o.yg)("a",{parentName:"p",href:"https://arxiv.org/abs/2205.14135"},"https://arxiv.org/abs/2205.14135")," for more details."))}Ue.isMDXComponent=!0;const qe={toc:[]},je="wrapper";function We(e){let{components:t,...n}=e;return(0,o.yg)(je,(0,a.A)({},qe,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the number of training examples a mini-batch uses during an iteration of the training model to estimate the error gradient before updating the model weights. ",(0,o.yg)("strong",{parentName:"p"},"Batch size")," defines the batch size used per a single GPU."),(0,o.yg)("p",null,"During model training, the training data is packed into mini-batches of a fixed size."))}We.isMDXComponent=!0;const Fe={toc:[]},Be="wrapper";function Ke(e){let{components:t,...n}=e;return(0,o.yg)(Be,(0,a.A)({},Fe,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the number of epochs to train the model. In other words, it specifies the number of times the learning algorithm goes through the entire training dataset."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"The ",(0,o.yg)("strong",{parentName:"li"},"Epochs")," setting is an important setting to tune because it balances under- and overfitting."),(0,o.yg)("li",{parentName:"ul"},"The learning rate highly impacts the optimal value of the epochs."),(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio enables you to utilize a pre-trained model trained on zero epochs (where H2O LLM Studio does not train the model and the pretrained model (experiment) can be evaluated as-is):")))}Ke.isMDXComponent=!0;const _e={toc:[]},Ve="wrapper";function Ye(e){let{components:t,...n}=e;return(0,o.yg)(Ve,(0,a.A)({},_e,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the learning rate schedule H2O LLM Studio utilizes during model training. Specifying a learning rate schedule prevents the learning rate from staying the same. Instead, a learning rate schedule causes the learning rate to change over iterations, typically decreasing the learning rate to achieve a better model performance and training convergence."),(0,o.yg)("p",null,"Options"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Constant"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio applies a constant learning rate during the training process."))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Cosine"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio applies a cosine learning rate that follows the values of the cosine function."))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Linear"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio applies a linear learning rate that decreases the learning rate linearly.")))))}Ye.isMDXComponent=!0;const Qe={toc:[]},Je="wrapper";function Ze(e){let{components:t,...n}=e;return(0,o.yg)(Je,(0,a.A)({},Qe,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the number of epochs to warm up the learning rate where the learning rate should increase linearly from 0 to the desired learning rate. Can be a fraction of an epoch."))}Ze.isMDXComponent=!0;const $e={toc:[]},et="wrapper";function tt(e){let{components:t,...n}=e;return(0,o.yg)(et,(0,a.A)({},$e,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the weight decay that H2O LLM Studio uses for the optimizer during model training."),(0,o.yg)("p",null,"Weight decay is a regularization technique that adds an L2 norm of all model weights to the loss function while increasing the probability of improving the model generalization."))}tt.isMDXComponent=!0;const nt={toc:[]},at="wrapper";function ot(e){let{components:t,...n}=e;return(0,o.yg)(at,(0,a.A)({},nt,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the maximum norm of the gradients H2O LLM Studio specifies during model training. Defaults to ",(0,o.yg)("strong",{parentName:"p"},"0"),", no clipping. When a value greater than 0 is specified, H2O LLM Studio modifies the gradients during model training. H2O LLM Studio uses the specified value as an upper limit for the norm of the gradients, calculated using the Euclidean norm over all gradients per batch."),(0,o.yg)("p",null,"This setting can help model convergence when extreme gradient values cause high volatility of weight updates."))}ot.isMDXComponent=!0;const it={toc:[]},rt="wrapper";function lt(e){let{components:t,...n}=e;return(0,o.yg)(rt,(0,a.A)({},it,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the number of gradient accumulations before H2O LLM Studio updates the neural network weights during model training."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Grad accumulation can be beneficial if only small batches are selected for training. With gradient accumulation, the loss and gradients are calculated after each batch, but it waits for the selected accumulations before updating the model weights. You can control the batch size through the ",(0,o.yg)("strong",{parentName:"li"},"Batch size")," setting."),(0,o.yg)("li",{parentName:"ul"},"Changing the default value of ",(0,o.yg)("em",{parentName:"li"},"Grad Accumulation")," might require adjusting the learning rate and batch size.")))}lt.isMDXComponent=!0;const st={toc:[]},pt="wrapper";function gt(e){let{components:t,...n}=e;return(0,o.yg)(pt,(0,a.A)({},st,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Whether to use low rank approximations (LoRA) during training."))}gt.isMDXComponent=!0;const ut={toc:[]},dt="wrapper";function mt(e){let{components:t,...n}=e;return(0,o.yg)(dt,(0,a.A)({},ut,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Enables Weight-Decomposed Low-Rank Adaptation (DoRA) to be used instead of low rank approximations (LoRA) during training. This parameter efficient training method is built on top of LoRA and has shown promising results. Especially at lower ranks (e.g. r=4), it is expected to perform superior to LoRA."))}mt.isMDXComponent=!0;const ct={toc:[]},yt="wrapper";function ht(e){let{components:t,...n}=e;return(0,o.yg)(yt,(0,a.A)({},ct,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The dimension of the matrix decomposition used in LoRA."))}ht.isMDXComponent=!0;const ft={toc:[]},vt="wrapper";function bt(e){let{components:t,...n}=e;return(0,o.yg)(vt,(0,a.A)({},ft,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The scaling factor for the lora weights."))}bt.isMDXComponent=!0;const Tt={toc:[]},xt="wrapper";function wt(e){let{components:t,...n}=e;return(0,o.yg)(xt,(0,a.A)({},Tt,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The probability of applying dropout to the LoRA weights during training."))}wt.isMDXComponent=!0;const Dt={toc:[]},Mt="wrapper";function Lt(e){let{components:t,...n}=e;return(0,o.yg)(Mt,(0,a.A)({},Dt,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The modules in the model to apply the LoRA approximation to. Defaults to all linear layers."))}Lt.isMDXComponent=!0;const Nt={toc:[]},At="wrapper";function St(e){let{components:t,...n}=e;return(0,o.yg)(At,(0,a.A)({},Nt,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"An optional list of backbone layers to unfreeze during training.\nBy default, all backbone layers are frozen when training with LoRA, here certain layers can be additionally trained, such as embedding or head layer.\nFull layer names will be matched against selected substrings. Only available with LoRA training."))}St.isMDXComponent=!0;const Xt={toc:[]},kt="wrapper";function Ct(e){let{components:t,...n}=e;return(0,o.yg)(kt,(0,a.A)({},Xt,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Specifies how H2O LLM Studio should save the model checkpoints."),(0,o.yg)("p",null,"When set to ",(0,o.yg)("strong",{parentName:"p"},"Last")," it will always save the last checkpoint, this is the recommended setting."),(0,o.yg)("p",null,"When set to ",(0,o.yg)("strong",{parentName:"p"},"Best")," it saves the model weights for the epoch exhibiting the best validation metric."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"This setting should be turned on with care as it has the potential to lead to overfitting of the validation data. "),(0,o.yg)("li",{parentName:"ul"},"The default goal should be to attempt to tune models so that the last epoch is the best epoch.  "),(0,o.yg)("li",{parentName:"ul"},"Suppose an evident decline for later epochs is observed in logging. In that case, it is usually better to adjust hyperparameters, such as reducing the number of epochs or increasing regularization, instead of turning this setting on.")),(0,o.yg)("p",null,"When set to ",(0,o.yg)("strong",{parentName:"p"},"Each evaluation epoch")," it will save the model weights for each evaluation epoch. "),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"This can be useful for debugging and experimenting, but will consume more disk space."),(0,o.yg)("li",{parentName:"ul"},"Models uploaded to Hugging Face Hub will only contain the last checkpoint."),(0,o.yg)("li",{parentName:"ul"},"Local downloads will contain all checkpoints.")),(0,o.yg)("p",null,"When set to ",(0,o.yg)("strong",{parentName:"p"},"Disable")," it will not save the checkpoint at all. This can be useful for debugging and experimenting in order to save disk space, but will disable certain functionalities like chatting or pushing to HF."))}Ct.isMDXComponent=!0;const Ot={toc:[]},Pt="wrapper";function zt(e){let{components:t,...n}=e;return(0,o.yg)(Pt,(0,a.A)({},Ot,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the number of epochs H2O LLM Studio uses before each validation loop for model training. In other words, it determines the frequency (in a number of epochs) to run the model evaluation on the validation data."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Increasing the number of ",(0,o.yg)("em",{parentName:"li"},"Evaluation Epochs")," can speed up an experiment."),(0,o.yg)("li",{parentName:"ul"},"The ",(0,o.yg)("strong",{parentName:"li"},"Evaluation epochs")," setting is available only if the following setting is turned ",(0,o.yg)("strong",{parentName:"li"},"Off"),": ",(0,o.yg)("strong",{parentName:"li"},"Save Best Checkpoint"),". "),(0,o.yg)("li",{parentName:"ul"},"Can be a fraction of an epoch")))}zt.isMDXComponent=!0;const Ht={toc:[]},Et="wrapper";function It(e){let{components:t,...n}=e;return(0,o.yg)(Et,(0,a.A)({},Ht,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"This option lets you evaluate the model before training, which can help you judge the quality of the LLM backbone before fine-tuning."))}It.isMDXComponent=!0;const Gt={toc:[]},Rt="wrapper";function Ut(e){let{components:t,...n}=e;return(0,o.yg)(Rt,(0,a.A)({},Gt,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines whether the model should use the entire train and validation dataset during model training. When turned ",(0,o.yg)("strong",{parentName:"p"},"On"),", H2O LLM Studio uses the whole train dataset and validation data to train the model."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio also evaluates the model on the provided validation fold. Validation is always only on the provided validation fold."),(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio uses both datasets for model training if you provide a train and validation dataset.",(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"To define a training dataset, use the ",(0,o.yg)("strong",{parentName:"li"},"Train dataframe")," setting."),(0,o.yg)("li",{parentName:"ul"},"To define a validation dataset, use the ",(0,o.yg)("strong",{parentName:"li"},"Validation dataframe")," setting."))),(0,o.yg)("li",{parentName:"ul"},"Turning ",(0,o.yg)("strong",{parentName:"li"},"On")," the ",(0,o.yg)("strong",{parentName:"li"},"Train validation data")," setting should produce a model that you can expect to perform better because H2O LLM Studio trained the model on more data. Though, also note that using the entire train dataset and validation dataset generally causes the model's accuracy to be ",(0,o.yg)("em",{parentName:"li"},"overstated")," as information from the validation data is incorporated into the model during the training process.")))}Ut.isMDXComponent=!0;const qt={toc:[]},jt="wrapper";function Wt(e){let{components:t,...n}=e;return(0,o.yg)(jt,(0,a.A)({},qt,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Toggle to enable Reinforcement Learning with Human Feedback."))}Wt.isMDXComponent=!0;const Ft={toc:[]},Bt="wrapper";function Kt(e){let{components:t,...n}=e;return(0,o.yg)(Bt,(0,a.A)({},Ft,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The ",(0,o.yg)("strong",{parentName:"p"},"Reward Model")," option is gives control over the models weights that shall be used to score the active LLM during RLHF training."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Any suited huggingface model can be used here (not limited to the ones in the dropdown list)")))}Kt.isMDXComponent=!0;const _t={toc:[]},Vt="wrapper";function Yt(e){let{components:t,...n}=e;return(0,o.yg)(Vt,(0,a.A)({},_t,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Initial KL penalty coefficient (used for adaptive and linear control)."))}Yt.isMDXComponent=!0;const Qt={toc:[]},Jt="wrapper";function Zt(e){let{components:t,...n}=e;return(0,o.yg)(Jt,(0,a.A)({},Qt,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Target KL value for adaptive KL control."))}Zt.isMDXComponent=!0;const $t={toc:[]},en="wrapper";function tn(e){let{components:t,...n}=e;return(0,o.yg)(en,(0,a.A)({},$t,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Horizon for adaptive KL control."))}tn.isMDXComponent=!0;const nn={toc:[]},an="wrapper";function on(e){let{components:t,...n}=e;return(0,o.yg)(an,(0,a.A)({},nn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Gamma parameter for advantage calculation."))}on.isMDXComponent=!0;const rn={toc:[]},ln="wrapper";function sn(e){let{components:t,...n}=e;return(0,o.yg)(ln,(0,a.A)({},rn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Lambda parameter for advantage calculation."))}sn.isMDXComponent=!0;const pn={toc:[]},gn="wrapper";function un(e){let{components:t,...n}=e;return(0,o.yg)(gn,(0,a.A)({},pn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Range for clipping in PPO policy gradient loss."))}un.isMDXComponent=!0;const dn={toc:[]},mn="wrapper";function cn(e){let{components:t,...n}=e;return(0,o.yg)(mn,(0,a.A)({},dn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Range for clipping values in loss calculation."))}cn.isMDXComponent=!0;const yn={toc:[]},hn="wrapper";function fn(e){let{components:t,...n}=e;return(0,o.yg)(hn,(0,a.A)({},yn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Scaling factor for value loss."))}fn.isMDXComponent=!0;const vn={toc:[]},bn="wrapper";function Tn(e){let{components:t,...n}=e;return(0,o.yg)(bn,(0,a.A)({},vn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Number of optimisation epochs per batch of samples."))}Tn.isMDXComponent=!0;const xn={toc:[]},wn="wrapper";function Dn(e){let{components:t,...n}=e;return(0,o.yg)(wn,(0,a.A)({},xn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Number of samples optimized inside PPO together."))}Dn.isMDXComponent=!0;const Mn={toc:[]},Ln="wrapper";function Nn(e){let{components:t,...n}=e;return(0,o.yg)(Ln,(0,a.A)({},Mn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"This is the temperature that is used in the generate function during the PPO Rollout."))}Nn.isMDXComponent=!0;const An={toc:[]},Sn="wrapper";function Xn(e){let{components:t,...n}=e;return(0,o.yg)(Sn,(0,a.A)({},An,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"When enabled, this will offload the reward model weights to CPU when not in use. This can be useful when training on a GPU with limited memory. The weights will be moved back to the GPU when needed."))}Xn.isMDXComponent=!0;const kn={toc:[]},Cn="wrapper";function On(e){let{components:t,...n}=e;return(0,o.yg)(Cn,(0,a.A)({},kn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the random probability of the input text tokens to be randomly masked during training. "),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Increasing this setting can be helpful to avoid overfitting and apply regularization"),(0,o.yg)("li",{parentName:"ul"},"Each token is randomly replaced by a masking token based on the specified probability")))}On.isMDXComponent=!0;const Pn={toc:[]},zn="wrapper";function Hn(e){let{components:t,...n}=e;return(0,o.yg)(zn,(0,a.A)({},Pn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"If ",(0,o.yg)("inlineCode",{parentName:"p"},"Parent Column")," is set, this random augmentation will skip parent concatenation during training at each parent with this specified probability."))}Hn.isMDXComponent=!0;const En={toc:[]},In="wrapper";function Gn(e){let{components:t,...n}=e;return(0,o.yg)(In,(0,a.A)({},En,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"While training, each sample will be concatenated to a random other sample simulating unrelated chained conversations. Can be specified without using a ",(0,o.yg)("inlineCode",{parentName:"p"},"Parent Column"),"."))}Gn.isMDXComponent=!0;const Rn={toc:[]},Un="wrapper";function qn(e){let{components:t,...n}=e;return(0,o.yg)(Un,(0,a.A)({},Rn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Will add noise to the input embeddings as proposed by ",(0,o.yg)("a",{parentName:"p",href:"https://arxiv.org/abs/2310.05914"},"https://arxiv.org/abs/2310.05914")," (NEFTune: Noisy Embeddings Improve Instruction Finetuning)"))}qn.isMDXComponent=!0;const jn={toc:[]},Wn="wrapper";function Fn(e){let{components:t,...n}=e;return(0,o.yg)(Wn,(0,a.A)({},jn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the metric to evaluate the model's performance. "),(0,o.yg)("p",null,"We provide several metric options for evaluating the performance of your model. The options depend on the selected Problem Type:"),(0,o.yg)("p",null,"Causal Language Modeling, DPO Modeling, Sequence to Sequence Modeling"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"In addition to the BLEU and the Perplexity score, we offer GPT metrics that utilize the OpenAI API to determine whether\nthe predicted answer is more favorable than the ground truth answer."),(0,o.yg)("li",{parentName:"ul"},"To use these metrics, you can either export your OpenAI API key as an environment variable before starting LLM Studio,\nor you can specify it in the Settings Menu within the UI.")),(0,o.yg)("p",null,"Causal Classification Modeling"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"AUC: Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)."),(0,o.yg)("li",{parentName:"ul"},"Accuracy: Compute the accuracy of the model."),(0,o.yg)("li",{parentName:"ul"},"LogLoss: Compute the log loss of the model.")))}Fn.isMDXComponent=!0;const Bn={toc:[]},Kn="wrapper";function _n(e){let{components:t,...n}=e;return(0,o.yg)(Kn,(0,a.A)({},Bn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the OpenAI model endpoint for the GPT metric."))}_n.isMDXComponent=!0;const Vn={toc:[]},Yn="wrapper";function Qn(e){let{components:t,...n}=e;return(0,o.yg)(Yn,(0,a.A)({},Vn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The template to use for GPT-based evaluation. Note that for mt-bench, the validation dataset will be replaced accordingly; to approximate the original implementation as close as possible, we suggest to use gpt-4-0613 as the gpt judge model and use 1024 for the max length inference."))}Qn.isMDXComponent=!0;const Jn={toc:[]},Zn="wrapper";function $n(e){let{components:t,...n}=e;return(0,o.yg)(Zn,(0,a.A)({},Jn,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the min length value H2O LLM Studio uses for the generated text."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"This setting impacts the evaluation metrics and should depend on the dataset and average output sequence length that is expected to be predicted.")))}$n.isMDXComponent=!0;const ea={toc:[]},ta="wrapper";function na(e){let{components:t,...n}=e;return(0,o.yg)(ta,(0,a.A)({},ea,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the max length value H2O LLM Studio uses for the generated text."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Similar to the ",(0,o.yg)("strong",{parentName:"li"},"Max Length")," setting in the ",(0,o.yg)("em",{parentName:"li"},"tokenizer settings")," section, this setting specifies the maximum number of tokens to predict for a given prediction sample."),(0,o.yg)("li",{parentName:"ul"},"This setting impacts the evaluation metrics and should depend on the dataset and average output sequence length that is expected to be predicted.")))}na.isMDXComponent=!0;const aa={toc:[]},oa="wrapper";function ia(e){let{components:t,...n}=e;return(0,o.yg)(oa,(0,a.A)({},aa,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the size of a mini-batch uses during an iteration of the inference. ",(0,o.yg)("strong",{parentName:"p"},"Batch size")," defines the batch size used per GPU."))}ia.isMDXComponent=!0;const ra={toc:[]},la="wrapper";function sa(e){let{components:t,...n}=e;return(0,o.yg)(la,(0,a.A)({},ra,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Determines whether to sample from the next token distribution instead of choosing the token with the highest probability. If turned ",(0,o.yg)("strong",{parentName:"p"},"On"),", the next token in a predicted sequence is sampled based on the probabilities. If turned ",(0,o.yg)("strong",{parentName:"p"},"Off"),", the highest probability is always chosen."))}sa.isMDXComponent=!0;const pa={toc:[]},ga="wrapper";function ua(e){let{components:t,...n}=e;return(0,o.yg)(ga,(0,a.A)({},pa,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the number of beams to use for beam search. ",(0,o.yg)("em",{parentName:"p"},"Num Beams")," default value is 1  (a single beam); no beam search."),(0,o.yg)("p",null,"A higher ",(0,o.yg)("em",{parentName:"p"},"Num Beams")," value can increase prediction runtime while potentially improving accuracy."))}ua.isMDXComponent=!0;const da={toc:[]},ma="wrapper";function ca(e){let{components:t,...n}=e;return(0,o.yg)(ma,(0,a.A)({},da,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the temperature to use for sampling from the next token distribution during validation and inference. In other words, the defined temperature controls the randomness of predictions by scaling the logits before applying ",(0,o.yg)("a",{href:"https://www.researchgate.net/figure/The-Gumbel-Softmax-distribution-interpolates-between-discrete-one-hot-encoded-categorical_fig4_309663606",target:"_blank"},"softmax"),". A higher temperature makes the distribution more random."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"Modify the temperature value if you have the ",(0,o.yg)("strong",{parentName:"li"},"Do Sample")," setting enabled (",(0,o.yg)("strong",{parentName:"li"},"On"),")."),(0,o.yg)("li",{parentName:"ul"},"To learn more about this setting, refer to the following article: ",(0,o.yg)("a",{href:"https://huggingface.co/blog/how-to-generate",target:"_blank"},"How to generate text: using different decoding methods for language generation with Transformers"),".")))}ca.isMDXComponent=!0;const ya={toc:[]},ha="wrapper";function fa(e){let{components:t,...n}=e;return(0,o.yg)(ha,(0,a.A)({},ya,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The parameter for repetition penalty. 1.0 means no penalty. See ",(0,o.yg)("a",{parentName:"p",href:"https://arxiv.org/pdf/1909.05858.pdf"},"https://arxiv.org/pdf/1909.05858.pdf")," for more details."))}fa.isMDXComponent=!0;const va={toc:[]},ba="wrapper";function Ta(e){let{components:t,...n}=e;return(0,o.yg)(ba,(0,a.A)({},va,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Will stop generation at occurrence of these additional tokens; multiple tokens should be split by comma ",(0,o.yg)("inlineCode",{parentName:"p"},","),"."))}Ta.isMDXComponent=!0;const xa={toc:[]},wa="wrapper";function Da(e){let{components:t,...n}=e;return(0,o.yg)(wa,(0,a.A)({},xa,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"If > 0, only keep the top k tokens with the highest probability (top-k filtering)."))}Da.isMDXComponent=!0;const Ma={toc:[]},La="wrapper";function Na(e){let{components:t,...n}=e;return(0,o.yg)(La,(0,a.A)({},Ma,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering)."))}Na.isMDXComponent=!0;const Aa={toc:[]},Sa="wrapper";function Xa(e){let{components:t,...n}=e;return(0,o.yg)(Sa,(0,a.A)({},Aa,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Determines the list of GPUs H2O LLM Studio can use for the experiment. GPUs are listed by name, referring to their system ID (starting from 1)."))}Xa.isMDXComponent=!0;const ka={toc:[]},Ca="wrapper";function Oa(e){let{components:t,...n}=e;return(0,o.yg)(Ca,(0,a.A)({},ka,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Determines whether to use mixed-precision. When turned ",(0,o.yg)("strong",{parentName:"p"},"Off"),", H2O LLM Studio does not use mixed-precision."),(0,o.yg)("p",null,"Mixed-precision is a technique that helps decrease memory consumption and increases training speed."))}Oa.isMDXComponent=!0;const Pa={toc:[]},za="wrapper";function Ha(e){let{components:t,...n}=e;return(0,o.yg)(za,(0,a.A)({},Pa,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Compiles the model with Torch. Experimental!"))}Ha.isMDXComponent=!0;const Ea={toc:[]},Ia="wrapper";function Ga(e){let{components:t,...n}=e;return(0,o.yg)(Ia,(0,a.A)({},Ea,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"In Distributed Data Parallel (DDP) mode, ",(0,o.yg)("inlineCode",{parentName:"p"},"prepare_for_backward()")," is called at the end of DDP forward pass. It traverses the autograd graph to find unused parameters when ",(0,o.yg)("inlineCode",{parentName:"p"},"find_unused_parameters")," is set to True in DDP constructor."),(0,o.yg)("p",null,"Note that traversing the autograd graph introduces extra overheads, so applications should only set to True when necessary."))}Ga.isMDXComponent=!0;const Ra={toc:[]},Ua="wrapper";function qa(e){let{components:t,...n}=e;return(0,o.yg)(Ua,(0,a.A)({},Ra,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Trust remote code. This can be necessary for some models that use code which is not (yet) part of the ",(0,o.yg)("inlineCode",{parentName:"p"},"transformers")," package. Should always be checked with this option being switched ",(0,o.yg)("strong",{parentName:"p"},"Off")," first."))}qa.isMDXComponent=!0;const ja={toc:[]},Wa="wrapper";function Fa(e){let{components:t,...n}=e;return(0,o.yg)(Wa,(0,a.A)({},ja,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The ",(0,o.yg)("strong",{parentName:"p"},"Huggingface Branch"),' defines which branch to use in a Huggingface repository. The default value is "main".'))}Fa.isMDXComponent=!0;const Ba={toc:[]},Ka="wrapper";function _a(e){let{components:t,...n}=e;return(0,o.yg)(Ka,(0,a.A)({},Ba,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the number of workers H2O LLM Studio uses for the ",(0,o.yg)("em",{parentName:"p"},"DataLoader"),". In other words, it defines the number of CPU processes to use when reading and loading data to GPUs during model training."))}_a.isMDXComponent=!0;const Va={toc:[]},Ya="wrapper";function Qa(e){let{components:t,...n}=e;return(0,o.yg)(Ya,(0,a.A)({},Va,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the random seed value that H2O LLM Studio uses during model training. It defaults to -1, an arbitrary value. When the value is modified (not -1), the random seed allows results to be reproducible\u2014defining a seed aids in obtaining predictable and repeatable results every time. Otherwise, not modifying the default seed value (-1) leads to random numbers at every invocation."))}Qa.isMDXComponent=!0;const Ja={toc:[]},Za="wrapper";function $a(e){let{components:t,...n}=e;return(0,o.yg)(Za,(0,a.A)({},Ja,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the logger type that H2O LLM Studio uses for model training"),(0,o.yg)("p",null,"Options"),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"None"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio does not use any logger."))),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("strong",{parentName:"li"},"Neptune"),(0,o.yg)("ul",{parentName:"li"},(0,o.yg)("li",{parentName:"ul"},"H2O LLM Studio uses Neptune as a logger to track the experiment. To use Neptune, you must specify a ",(0,o.yg)("strong",{parentName:"li"},"Neptune API token")," and a ",(0,o.yg)("strong",{parentName:"li"},"Neptune project"),".")))))}$a.isMDXComponent=!0;const eo={toc:[]},to="wrapper";function no(e){let{components:t,...n}=e;return(0,o.yg)(to,(0,a.A)({},eo,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the ",(0,o.yg)("a",{href:"https://neptune.ai/",target:"_blank"},"Neptune")," project to access if you selected Neptune in the ",(0,o.yg)("strong",{parentName:"p"},"Logger")," setting."))}no.isMDXComponent=!0;const ao={description:"All the settings needed for creating an experiment are explored in this page."},oo="Experiment settings",io={unversionedId:"guide/experiments/experiment-settings",id:"guide/experiments/experiment-settings",title:"Experiment settings",description:"All the settings needed for creating an experiment are explored in this page.",source:"@site/docs/guide/experiments/experiment-settings.md",sourceDirName:"guide/experiments",slug:"/guide/experiments/experiment-settings",permalink:"/h2o-llmstudio/guide/experiments/experiment-settings",draft:!1,tags:[],version:"current",frontMatter:{description:"All the settings needed for creating an experiment are explored in this page."},sidebar:"defaultSidebar",previous:{title:"Merge datasets",permalink:"/h2o-llmstudio/guide/datasets/merge-datasets"},next:{title:"Create an experiment",permalink:"/h2o-llmstudio/guide/experiments/create-an-experiment"}},ro={},lo=[{value:"General settings",id:"general-settings",level:2},{value:"Dataset",id:"dataset",level:3},{value:"Problem type",id:"problem-type",level:3},{value:"Import config from YAML",id:"import-config-from-yaml",level:3},{value:"Experiment name",id:"experiment-name",level:3},{value:"LLM backbone",id:"llm-backbone",level:3},{value:"Dataset settings",id:"dataset-settings",level:2},{value:"Train dataframe",id:"train-dataframe",level:3},{value:"Validation strategy",id:"validation-strategy",level:3},{value:"Validation size",id:"validation-size",level:3},{value:"Data sample",id:"data-sample",level:3},{value:"System column",id:"system-column",level:3},{value:"Prompt column",id:"prompt-column",level:3},{value:"Answer column",id:"answer-column",level:3},{value:"Parent ID column",id:"parent-id-column",level:3},{value:"Text prompt start",id:"text-prompt-start",level:3},{value:"Text answer separator",id:"text-answer-separator",level:3},{value:"Adaptive Kl control",id:"adaptive-kl-control",level:2},{value:"Add EOS token to prompt",id:"add-eos-token-to-prompt",level:3},{value:"Add EOS token to answer",id:"add-eos-token-to-answer",level:3},{value:"Mask prompt labels",id:"mask-prompt-labels",level:3},{value:"Tokenizer settings",id:"tokenizer-settings",level:2},{value:"Max length prompt",id:"max-length-prompt",level:3},{value:"Max length answer",id:"max-length-answer",level:3},{value:"Max length",id:"max-length",level:3},{value:"Add prompt answer tokens",id:"add-prompt-answer-tokens",level:3},{value:"Padding quantile",id:"padding-quantile",level:3},{value:"Architecture settings",id:"architecture-settings",level:2},{value:"Backbone Dtype",id:"backbone-dtype",level:3},{value:"Gradient Checkpointing",id:"gradient-checkpointing",level:3},{value:"Intermediate dropout",id:"intermediate-dropout",level:3},{value:"Pretrained weights",id:"pretrained-weights",level:3},{value:"Training settings",id:"training-settings",level:2},{value:"Loss function",id:"loss-function",level:3},{value:"Optimizer",id:"optimizer",level:3},{value:"Learning rate",id:"learning-rate",level:3},{value:"Differential learning rate layers",id:"differential-learning-rate-layers",level:3},{value:"Freeze layers",id:"freeze-layers",level:3},{value:"Use Flash Attention 2",id:"use-flash-attention-2",level:3},{value:"Batch size",id:"batch-size",level:3},{value:"Epochs",id:"epochs",level:3},{value:"Schedule",id:"schedule",level:3},{value:"Warmup epochs",id:"warmup-epochs",level:3},{value:"Weight decay",id:"weight-decay",level:3},{value:"Gradient clip",id:"gradient-clip",level:3},{value:"Grad accumulation",id:"grad-accumulation",level:3},{value:"Lora",id:"lora",level:3},{value:"Use Dora",id:"use-dora",level:3},{value:"Lora R",id:"lora-r",level:3},{value:"Lora Alpha",id:"lora-alpha",level:3},{value:"Lora dropout",id:"lora-dropout",level:3},{value:"Lora target modules",id:"lora-target-modules",level:3},{value:"Lora unfreeze layers",id:"lora-unfreeze-layers",level:3},{value:"Save checkpoint",id:"save-checkpoint",level:3},{value:"Evaluation epochs",id:"evaluation-epochs",level:3},{value:"Evaluate before training",id:"evaluate-before-training",level:3},{value:"Train validation data",id:"train-validation-data",level:3},{value:"Use RLHF",id:"use-rlhf",level:3},{value:"Reward model",id:"reward-model",level:3},{value:"Adaptive KL control",id:"adaptive-kl-control-1",level:3},{value:"Initial KL coefficient",id:"initial-kl-coefficient",level:3},{value:"KL target",id:"kl-target",level:3},{value:"KL Horizon",id:"kl-horizon",level:3},{value:"Advantages gamma",id:"advantages-gamma",level:3},{value:"Advantages Lambda",id:"advantages-lambda",level:3},{value:"PPO clip policy",id:"ppo-clip-policy",level:3},{value:"PPO clip value",id:"ppo-clip-value",level:3},{value:"Scaling factor value loss",id:"scaling-factor-value-loss",level:3},{value:"PPO epochs",id:"ppo-epochs",level:3},{value:"PPO Batch Size",id:"ppo-batch-size",level:3},{value:"PPO generate temperature",id:"ppo-generate-temperature",level:3},{value:"Offload reward model",id:"offload-reward-model",level:3},{value:"Augmentation settings",id:"augmentation-settings",level:2},{value:"Token mask probability",id:"token-mask-probability",level:3},{value:"Skip parent probability",id:"skip-parent-probability",level:3},{value:"Random parent probability",id:"random-parent-probability",level:3},{value:"Neftune noise alpha",id:"neftune-noise-alpha",level:3},{value:"Prediction settings",id:"prediction-settings",level:2},{value:"Metric",id:"metric",level:3},{value:"Metric GPT model",id:"metric-gpt-model",level:3},{value:"Metric GPT template",id:"metric-gpt-template",level:3},{value:"Min length inference",id:"min-length-inference",level:3},{value:"Max length inference",id:"max-length-inference",level:3},{value:"Batch size inference",id:"batch-size-inference",level:3},{value:"Do sample",id:"do-sample",level:3},{value:"Num beams",id:"num-beams",level:3},{value:"Temperature",id:"temperature",level:3},{value:"Repetition penalty",id:"repetition-penalty",level:3},{value:"Stop tokens",id:"stop-tokens",level:3},{value:"Top K",id:"top-k",level:3},{value:"Top P",id:"top-p",level:3},{value:"Environment settings",id:"environment-settings",level:2},{value:"GPUs",id:"gpus",level:3},{value:"Mixed precision",id:"mixed-precision",level:3},{value:"Compile model",id:"compile-model",level:3},{value:"Find unused parameters",id:"find-unused-parameters",level:3},{value:"Trust remote code",id:"trust-remote-code",level:3},{value:"Huggingface branch",id:"huggingface-branch",level:3},{value:"Number of workers",id:"number-of-workers",level:3},{value:"Seed",id:"seed",level:3},{value:"Logging settings",id:"logging-settings",level:2},{value:"Logger",id:"logger",level:3},{value:"Neptune project",id:"neptune-project",level:3}],so={toc:lo},po="wrapper";function go(e){let{components:t,...n}=e;return(0,o.yg)(po,(0,a.A)({},so,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("h1",{id:"experiment-settings"},"Experiment settings"),(0,o.yg)("p",null,"The settings for creating an experiment are grouped into the following sections: "),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#general-settings"},"General settings")," "),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#dataset-settings"},"Dataset settings")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#tokenizer-settings"},"Tokenizer settings")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#architecture-settings"},"Architecture settings")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#training-settings"},"Training settings")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#augmentation-settings"},"Augmentation settings")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#prediction-settings"},"Prediction settings")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#environment-settings"},"Environment settings")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("a",{parentName:"li",href:"#logging-settings"},"Logging settings"))),(0,o.yg)("p",null,"The settings under each category are listed and described below."),(0,o.yg)("h2",{id:"general-settings"},"General settings"),(0,o.yg)("h3",{id:"dataset"},"Dataset"),(0,o.yg)(l,{mdxType:"GeneralSettingsDataset"}),(0,o.yg)("h3",{id:"problem-type"},"Problem type"),(0,o.yg)(s.Ay,{mdxType:"GeneralSettingsProblemType"}),(0,o.yg)("h3",{id:"import-config-from-yaml"},"Import config from YAML"),(0,o.yg)(u,{mdxType:"GSImportConfigFromYaml"}),(0,o.yg)("h3",{id:"experiment-name"},"Experiment name"),(0,o.yg)(c,{mdxType:"GSExperimentName"}),(0,o.yg)("h3",{id:"llm-backbone"},"LLM backbone"),(0,o.yg)(f,{mdxType:"GSLLMBackbone"}),(0,o.yg)("h2",{id:"dataset-settings"},"Dataset settings"),(0,o.yg)("h3",{id:"train-dataframe"},"Train dataframe"),(0,o.yg)(v.Ay,{mdxType:"DSTrainDataframe"}),(0,o.yg)("h3",{id:"validation-strategy"},"Validation strategy"),(0,o.yg)(x,{mdxType:"DSvalidationStrategy"}),(0,o.yg)("h3",{id:"validation-size"},"Validation size"),(0,o.yg)(M,{mdxType:"DSvalidationSize"}),(0,o.yg)("h3",{id:"data-sample"},"Data sample"),(0,o.yg)(A,{mdxType:"DSdataSample"}),(0,o.yg)("h3",{id:"system-column"},"System column"),(0,o.yg)(X.Ay,{mdxType:"DSsystemColumn"}),(0,o.yg)("h3",{id:"prompt-column"},"Prompt column"),(0,o.yg)(S.Ay,{mdxType:"DSpromptColumn"}),(0,o.yg)("h3",{id:"answer-column"},"Answer column"),(0,o.yg)(k.Ay,{mdxType:"DSanswerColumn"}),(0,o.yg)("h3",{id:"parent-id-column"},"Parent ID column"),(0,o.yg)(C.Ay,{mdxType:"DSparentIdColumn"}),(0,o.yg)("h3",{id:"text-prompt-start"},"Text prompt start"),(0,o.yg)(z,{mdxType:"DStextPromptStart"}),(0,o.yg)("h3",{id:"text-answer-separator"},"Text answer separator"),(0,o.yg)(I,{mdxType:"DStextAnswerSeparator"}),(0,o.yg)("h2",{id:"adaptive-kl-control"},"Adaptive Kl control"),(0,o.yg)(U,{mdxType:"DSadaptiveKlControl"}),(0,o.yg)("h3",{id:"add-eos-token-to-prompt"},"Add EOS token to prompt"),(0,o.yg)(W,{mdxType:"DSaddEosTokentoprompt"}),(0,o.yg)("h3",{id:"add-eos-token-to-answer"},"Add EOS token to answer"),(0,o.yg)(K,{mdxType:"DSaddEosTokentoanswer"}),(0,o.yg)("h3",{id:"mask-prompt-labels"},"Mask prompt labels"),(0,o.yg)(Y,{mdxType:"DSmaskPromptlabels"}),(0,o.yg)("h2",{id:"tokenizer-settings"},"Tokenizer settings"),(0,o.yg)("h3",{id:"max-length-prompt"},"Max length prompt"),(0,o.yg)(Z,{mdxType:"TSmaxLengthPrompt"}),(0,o.yg)("h3",{id:"max-length-answer"},"Max length answer"),(0,o.yg)(te,{mdxType:"TSmaxLengthAnswer"}),(0,o.yg)("h3",{id:"max-length"},"Max length"),(0,o.yg)(oe,{mdxType:"TSmaxLength"}),(0,o.yg)("h3",{id:"add-prompt-answer-tokens"},"Add prompt answer tokens"),(0,o.yg)(le,{mdxType:"TSaddpromptanswertokens"}),(0,o.yg)("h3",{id:"padding-quantile"},"Padding quantile"),(0,o.yg)(ge,{mdxType:"TSpaddingQuantile"}),(0,o.yg)("h2",{id:"architecture-settings"},"Architecture settings"),(0,o.yg)("h3",{id:"backbone-dtype"},"Backbone Dtype"),(0,o.yg)(me,{mdxType:"ASBackboneDtype"}),(0,o.yg)("h3",{id:"gradient-checkpointing"},"Gradient Checkpointing"),(0,o.yg)(he,{mdxType:"ASGradientcheckpointing"}),(0,o.yg)("h3",{id:"intermediate-dropout"},"Intermediate dropout"),(0,o.yg)(be,{mdxType:"ASintermediateDropout"}),(0,o.yg)("h3",{id:"pretrained-weights"},"Pretrained weights"),(0,o.yg)(we,{mdxType:"ASpretrainedWeights"}),(0,o.yg)("h2",{id:"training-settings"},"Training settings"),(0,o.yg)("h3",{id:"loss-function"},"Loss function"),(0,o.yg)(Se,{mdxType:"TSlossfunction"}),(0,o.yg)("h3",{id:"optimizer"},"Optimizer"),(0,o.yg)(Le,{mdxType:"TSoptimizer"}),(0,o.yg)("h3",{id:"learning-rate"},"Learning rate"),(0,o.yg)(Ce,{mdxType:"TSlearningRate"}),(0,o.yg)("h3",{id:"differential-learning-rate-layers"},"Differential learning rate layers"),(0,o.yg)(ze,{mdxType:"TSdifferentialLearningRateLayers"}),(0,o.yg)("h3",{id:"freeze-layers"},"Freeze layers"),(0,o.yg)(Ie,{mdxType:"TSfreezeLayers"}),(0,o.yg)("h3",{id:"use-flash-attention-2"},"Use Flash Attention 2"),(0,o.yg)(Ue,{mdxType:"TSuseflashattention2"}),(0,o.yg)("h3",{id:"batch-size"},"Batch size"),(0,o.yg)(We,{mdxType:"TSbatchSize"}),(0,o.yg)("h3",{id:"epochs"},"Epochs"),(0,o.yg)(Ke,{mdxType:"TSepochs"}),(0,o.yg)("h3",{id:"schedule"},"Schedule"),(0,o.yg)(Ye,{mdxType:"TSschedule"}),(0,o.yg)("h3",{id:"warmup-epochs"},"Warmup epochs"),(0,o.yg)(Ze,{mdxType:"TSwarmupEpochs"}),(0,o.yg)("h3",{id:"weight-decay"},"Weight decay"),(0,o.yg)(tt,{mdxType:"TSweightDecay"}),(0,o.yg)("h3",{id:"gradient-clip"},"Gradient clip"),(0,o.yg)(ot,{mdxType:"TSGradientclip"}),(0,o.yg)("h3",{id:"grad-accumulation"},"Grad accumulation"),(0,o.yg)(lt,{mdxType:"TSgradAccumulation"}),(0,o.yg)("h3",{id:"lora"},"Lora"),(0,o.yg)(gt,{mdxType:"TSlora"}),(0,o.yg)("h3",{id:"use-dora"},"Use Dora"),(0,o.yg)(mt,{mdxType:"TSuseDora"}),(0,o.yg)("h3",{id:"lora-r"},"Lora R"),(0,o.yg)(ht,{mdxType:"TSloraR"}),(0,o.yg)("h3",{id:"lora-alpha"},"Lora Alpha"),(0,o.yg)(bt,{mdxType:"TSloraAlpha"}),(0,o.yg)("h3",{id:"lora-dropout"},"Lora dropout"),(0,o.yg)(wt,{mdxType:"TSloraDropout"}),(0,o.yg)("h3",{id:"lora-target-modules"},"Lora target modules"),(0,o.yg)(Lt,{mdxType:"TSloraTargetModules"}),(0,o.yg)("h3",{id:"lora-unfreeze-layers"},"Lora unfreeze layers"),(0,o.yg)(St,{mdxType:"TSloraUnfreezeLayers"}),(0,o.yg)("p",null,"TSloraUnfreezeLayers"),(0,o.yg)("h3",{id:"save-checkpoint"},"Save checkpoint"),(0,o.yg)(Ct,{mdxType:"TSsavecheckpoint"}),(0,o.yg)("h3",{id:"evaluation-epochs"},"Evaluation epochs"),(0,o.yg)(zt,{mdxType:"TSevaluationepochs"}),(0,o.yg)("h3",{id:"evaluate-before-training"},"Evaluate before training"),(0,o.yg)(It,{mdxType:"TSevaluationbeforetraining"}),(0,o.yg)("h3",{id:"train-validation-data"},"Train validation data"),(0,o.yg)(Ut,{mdxType:"TStrainvalidationdata"}),(0,o.yg)("h3",{id:"use-rlhf"},"Use RLHF"),(0,o.yg)(Wt,{mdxType:"TSuseRHLF"}),(0,o.yg)("h3",{id:"reward-model"},"Reward model"),(0,o.yg)(Kt,{mdxType:"TSrewardModel"}),(0,o.yg)("h3",{id:"adaptive-kl-control-1"},"Adaptive KL control"),(0,o.yg)(U,{mdxType:"DSadaptiveKlControl"}),(0,o.yg)("h3",{id:"initial-kl-coefficient"},"Initial KL coefficient"),(0,o.yg)(Yt,{mdxType:"TSinitialKlCoefficient"}),(0,o.yg)("h3",{id:"kl-target"},"KL target"),(0,o.yg)(Zt,{mdxType:"TSklTarget"}),(0,o.yg)("h3",{id:"kl-horizon"},"KL Horizon"),(0,o.yg)(tn,{mdxType:"TSklHorizon"}),(0,o.yg)("h3",{id:"advantages-gamma"},"Advantages gamma"),(0,o.yg)(on,{mdxType:"TSadvantagesGamma"}),(0,o.yg)("h3",{id:"advantages-lambda"},"Advantages Lambda"),(0,o.yg)(sn,{mdxType:"TSadvantagesLambda"}),(0,o.yg)("h3",{id:"ppo-clip-policy"},"PPO clip policy"),(0,o.yg)(un,{mdxType:"TSppoClipPolicy"}),(0,o.yg)("h3",{id:"ppo-clip-value"},"PPO clip value"),(0,o.yg)(cn,{mdxType:"TSppoClipValue"}),(0,o.yg)("h3",{id:"scaling-factor-value-loss"},"Scaling factor value loss"),(0,o.yg)(fn,{mdxType:"TSscalingFactorValueLoss"}),(0,o.yg)("h3",{id:"ppo-epochs"},"PPO epochs"),(0,o.yg)(Tn,{mdxType:"TSppoEpochs"}),(0,o.yg)("h3",{id:"ppo-batch-size"},"PPO Batch Size"),(0,o.yg)(Dn,{mdxType:"TSppoBatchSize"}),(0,o.yg)("h3",{id:"ppo-generate-temperature"},"PPO generate temperature"),(0,o.yg)(Nn,{mdxType:"TSppoGenerateTemp"}),(0,o.yg)("h3",{id:"offload-reward-model"},"Offload reward model"),(0,o.yg)(Xn,{mdxType:"TSoffloadRewardModel"}),(0,o.yg)("h2",{id:"augmentation-settings"},"Augmentation settings"),(0,o.yg)("h3",{id:"token-mask-probability"},"Token mask probability"),(0,o.yg)(On,{mdxType:"AStokenmaskprobability"}),(0,o.yg)("h3",{id:"skip-parent-probability"},"Skip parent probability"),(0,o.yg)(Hn,{mdxType:"ASskipParentprobability"}),(0,o.yg)("h3",{id:"random-parent-probability"},"Random parent probability"),(0,o.yg)(Gn,{mdxType:"ASrandomparentprobability"}),(0,o.yg)("h3",{id:"neftune-noise-alpha"},"Neftune noise alpha"),(0,o.yg)(qn,{mdxType:"ASneftunenoisealpha"}),(0,o.yg)("h2",{id:"prediction-settings"},"Prediction settings"),(0,o.yg)("h3",{id:"metric"},"Metric"),(0,o.yg)(Fn,{mdxType:"PSmetric"}),(0,o.yg)("h3",{id:"metric-gpt-model"},"Metric GPT model"),(0,o.yg)(_n,{mdxType:"PSmetricgptmodel"}),(0,o.yg)("h3",{id:"metric-gpt-template"},"Metric GPT template"),(0,o.yg)(Qn,{mdxType:"PSmetricgpttemplate"}),(0,o.yg)("h3",{id:"min-length-inference"},"Min length inference"),(0,o.yg)($n,{mdxType:"PSminlengthinference"}),(0,o.yg)("h3",{id:"max-length-inference"},"Max length inference"),(0,o.yg)(na,{mdxType:"PSmaxlengthinference"}),(0,o.yg)("h3",{id:"batch-size-inference"},"Batch size inference"),(0,o.yg)(ia,{mdxType:"PSbatchsizeinference"}),(0,o.yg)("h3",{id:"do-sample"},"Do sample"),(0,o.yg)(sa,{mdxType:"PSdosample"}),(0,o.yg)("h3",{id:"num-beams"},"Num beams"),(0,o.yg)(ua,{mdxType:"PSnumbeams"}),(0,o.yg)("h3",{id:"temperature"},"Temperature"),(0,o.yg)(ca,{mdxType:"PStemperature"}),(0,o.yg)("h3",{id:"repetition-penalty"},"Repetition penalty"),(0,o.yg)(fa,{mdxType:"PSrepetitionpenalty"}),(0,o.yg)("h3",{id:"stop-tokens"},"Stop tokens"),(0,o.yg)(Ta,{mdxType:"PSstoptokens"}),(0,o.yg)("h3",{id:"top-k"},"Top K"),(0,o.yg)(Da,{mdxType:"PStopk"}),(0,o.yg)("h3",{id:"top-p"},"Top P"),(0,o.yg)(Na,{mdxType:"PStopp"}),(0,o.yg)("h2",{id:"environment-settings"},"Environment settings"),(0,o.yg)("h3",{id:"gpus"},"GPUs"),(0,o.yg)(Xa,{mdxType:"ESgpus"}),(0,o.yg)("h3",{id:"mixed-precision"},"Mixed precision"),(0,o.yg)(Oa,{mdxType:"ESmixedprecision"}),(0,o.yg)("h3",{id:"compile-model"},"Compile model"),(0,o.yg)(Ha,{mdxType:"EScompilemodel"}),(0,o.yg)("h3",{id:"find-unused-parameters"},"Find unused parameters"),(0,o.yg)(Ga,{mdxType:"ESfindunusedparameters"}),(0,o.yg)("h3",{id:"trust-remote-code"},"Trust remote code"),(0,o.yg)(qa,{mdxType:"EStrustremotecode"}),(0,o.yg)("h3",{id:"huggingface-branch"},"Huggingface branch"),(0,o.yg)(Fa,{mdxType:"EShuggingfacebranch"}),(0,o.yg)("h3",{id:"number-of-workers"},"Number of workers"),(0,o.yg)(_a,{mdxType:"ESnumofworkers"}),(0,o.yg)("h3",{id:"seed"},"Seed"),(0,o.yg)(Qa,{mdxType:"ESseed"}),(0,o.yg)("h2",{id:"logging-settings"},"Logging settings"),(0,o.yg)("h3",{id:"logger"},"Logger"),(0,o.yg)($a,{mdxType:"LSlogger"}),(0,o.yg)("h3",{id:"neptune-project"},"Neptune project"),(0,o.yg)(no,{mdxType:"LSneptuneproject"}))}go.isMDXComponent=!0},5690:(e,t,n)=>{n.d(t,{Ay:()=>l});var a=n(8168),o=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,o.yg)(r,(0,a.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The column in the dataset containing the expected output."),(0,o.yg)("p",null,"For classification, this needs to be an integer column containing the class label."))}l.isMDXComponent=!0},5482:(e,t,n)=>{n.d(t,{Ay:()=>l});var a=n(8168),o=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,o.yg)(r,(0,a.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"An optional column specifying the parent id to be used for chained conversations. The value of this column needs to match an additional column with the name ",(0,o.yg)("inlineCode",{parentName:"p"},"id"),". If provided, the prompt will be concatenated after preceding parent rows."))}l.isMDXComponent=!0},2073:(e,t,n)=>{n.d(t,{Ay:()=>l});var a=n(8168),o=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,o.yg)(r,(0,a.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines the problem type of the experiment, which also defines the settings H2O LLM Studio displays for the experiment."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("p",{parentName:"li"},"Causal Language Modeling: Used to fine-tune large language models")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("p",{parentName:"li"},"DPO Modeling: Used to fine-tune large language models using Direct Preference Optimization")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("p",{parentName:"li"},"Sequence To Sequence Modeling: Used to fine-tune large sequence to sequence models")),(0,o.yg)("li",{parentName:"ul"},(0,o.yg)("p",{parentName:"li"},"Causal Classification Modeling: Used to fine-tune causal classification models"))))}l.isMDXComponent=!0},5886:(e,t,n)=>{n.d(t,{Ay:()=>l});var a=n(8168),o=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,o.yg)(r,(0,a.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The column in the dataset containing the user prompt."))}l.isMDXComponent=!0},8017:(e,t,n)=>{n.d(t,{Ay:()=>l});var a=n(8168),o=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,o.yg)(r,(0,a.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"The column in the dataset containing the system input which is always prepended for a full sample."))}l.isMDXComponent=!0},3385:(e,t,n)=>{n.d(t,{Ay:()=>l});var a=n(8168),o=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,o.yg)(r,(0,a.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,o.yg)("p",null,"Defines a ",(0,o.yg)("inlineCode",{parentName:"p"},".csv")," or ",(0,o.yg)("inlineCode",{parentName:"p"},".pq")," file containing a dataframe with training records that H2O LLM Studio uses to ",(0,o.yg)("em",{parentName:"p"},"train")," the model."),(0,o.yg)("ul",null,(0,o.yg)("li",{parentName:"ul"},"The records are combined into mini-batches when training the model.")))}l.isMDXComponent=!0}}]);