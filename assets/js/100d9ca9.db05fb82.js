"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[178],{5680:(e,t,n)=>{n.d(t,{xA:()=>g,yg:()=>c});var o=n(6540);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=o.createContext({}),p=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},g=function(e){var t=p(e.components);return o.createElement(s.Provider,{value:t},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},u=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,g=l(e,["components","mdxType","originalType","parentName"]),d=p(n),u=a,c=d["".concat(s,".").concat(u)]||d[u]||m[u]||i;return n?o.createElement(c,r(r({ref:t},g),{},{components:n})):o.createElement(c,r({ref:t},g))}));function c(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,r=new Array(i);r[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[d]="string"==typeof e?e:a,r[1]=l;for(var p=2;p<i;p++)r[p]=n[p];return o.createElement.apply(null,r)}return o.createElement.apply(null,n)}u.displayName="MDXCreateElement"},562:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>ia,contentTitle:()=>oa,default:()=>pa,frontMatter:()=>na,metadata:()=>aa,toc:()=>ra});var o=n(8168),a=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.yg)(r,(0,o.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"It defines the dataset for the experiment."))}l.isMDXComponent=!0;const s={toc:[]},p="wrapper";function g(e){let{components:t,...n}=e;return(0,a.yg)(p,(0,o.A)({},s,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the problem type of the experiment, which also defines the settings H2O LLM Studio displays for the experiment."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Causal Language Modeling: Used to fine-tune large language models")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"DPO Modeling: Used to fine-tune large language models using Direct Preference Optimization")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Sequence To Sequence Modeling: Used to fine-tune large sequence to sequence models")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},"Causal Classification Modeling: Used to fine-tune causal classification models"))))}g.isMDXComponent=!0;const d={toc:[]},m="wrapper";function u(e){let{components:t,...n}=e;return(0,a.yg)(m,(0,o.A)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the ",(0,a.yg)("inlineCode",{parentName:"p"},".yml")," file that defines the experiment settings. "),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio supports a ",(0,a.yg)("inlineCode",{parentName:"li"},".yml")," file import and export functionality. You can download the config settings of finished experiments, make changes, and re-upload them when starting a new experiment in any instance of H2O LLM Studio.")))}u.isMDXComponent=!0;const c={toc:[]},y="wrapper";function h(e){let{components:t,...n}=e;return(0,a.yg)(y,(0,o.A)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"It defines the name of the experiment."))}h.isMDXComponent=!0;const f={toc:[]},v="wrapper";function b(e){let{components:t,...n}=e;return(0,a.yg)(v,(0,o.A)({},f,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The ",(0,a.yg)("strong",{parentName:"p"},"LLM Backbone")," option is the most important setting as it sets the pretrained model weights."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Usually, it is good to use smaller architectures for quicker experiments and larger models when aiming for the highest accuracy"),(0,a.yg)("li",{parentName:"ul"},"If possible, leverage backbones pre-trained closely to your use case"),(0,a.yg)("li",{parentName:"ul"},"Any huggingface model can be used here (not limited to the ones in the dropdown list)")))}b.isMDXComponent=!0;var T=n(3385);const x={toc:[]},w="wrapper";function M(e){let{components:t,...n}=e;return(0,a.yg)(w,(0,o.A)({},x,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Specifies the validation strategy H2O LLM Studio uses for the experiment."),(0,a.yg)("p",null,"To properly assess the performance of your trained models, it is common practice to evaluate it on separate holdout data that the model has not seen during training. H2O LLM Studio allows you to specify different strategies for this task fitting your needs."),(0,a.yg)("p",null,"Options"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Custom holdout validation"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Specifies a separate holdout dataframe."))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Automatic holdout validation"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"Allows to specify a holdout validation sample size that is automatically generated.")))))}M.isMDXComponent=!0;const D={toc:[]},L="wrapper";function N(e){let{components:t,...n}=e;return(0,a.yg)(L,(0,o.A)({},D,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines an optional relative size of the holdout validation set. H2O LLM Studio do automatically sample the selected\npercentage from the full training data, and build a holdout dataset that the model is validated on."))}N.isMDXComponent=!0;const S={toc:[]},A="wrapper";function X(e){let{components:t,...n}=e;return(0,a.yg)(A,(0,o.A)({},S,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the percentage of the data to use for the experiment. The default percentage is 100% (1)."),(0,a.yg)("p",null,"Changing the default value can significantly increase the training speed. Still, it might lead to a substantially poor accuracy value. Using 100% (1) of the data for final models is highly recommended."))}X.isMDXComponent=!0;var k=n(5886);const C={toc:[]},O="wrapper";function P(e){let{components:t,...n}=e;return(0,a.yg)(O,(0,o.A)({},C,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The column in the dataset containing the system input which is always prepended for a full sample."))}P.isMDXComponent=!0;var z=n(5690),E=n(5482);const H={toc:[]},G="wrapper";function I(e){let{components:t,...n}=e;return(0,a.yg)(G,(0,o.A)({},H,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Optional text to prepend to each prompt."))}I.isMDXComponent=!0;const R={toc:[]},q="wrapper";function U(e){let{components:t,...n}=e;return(0,a.yg)(q,(0,o.A)({},R,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Optional text to append to each prompt / prepend to each answer."))}U.isMDXComponent=!0;const j={toc:[]},W="wrapper";function F(e){let{components:t,...n}=e;return(0,a.yg)(W,(0,o.A)({},j,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Use adaptive KL control, otherwise linear."))}F.isMDXComponent=!0;const B={toc:[]},K="wrapper";function _(e){let{components:t,...n}=e;return(0,a.yg)(K,(0,o.A)({},B,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Adds EOS token at end of prompt."))}_.isMDXComponent=!0;const V={toc:[]},Y="wrapper";function Q(e){let{components:t,...n}=e;return(0,a.yg)(Y,(0,o.A)({},V,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Adds EOS token at end of answer."))}Q.isMDXComponent=!0;const J={toc:[]},Z="wrapper";function $(e){let{components:t,...n}=e;return(0,a.yg)(Z,(0,o.A)({},J,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Whether to mask the prompt labels during training and only train on the loss of the answer."))}$.isMDXComponent=!0;const ee={toc:[]},te="wrapper";function ne(e){let{components:t,...n}=e;return(0,a.yg)(te,(0,o.A)({},ee,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The maximum sequence length of the prompt to use during training. In case of chained samples, this max length refers to a single prompt length in the chain."))}ne.isMDXComponent=!0;const oe={toc:[]},ae="wrapper";function ie(e){let{components:t,...n}=e;return(0,a.yg)(ae,(0,o.A)({},oe,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The maximum sequence length of the answer to use during training. In case of chained samples, this max length refers to a single answer length in the chain."))}ie.isMDXComponent=!0;const re={toc:[]},le="wrapper";function se(e){let{components:t,...n}=e;return(0,a.yg)(le,(0,o.A)({},re,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the maximum length of the input sequence H2O LLM Studio uses during model training. In other words, this setting specifies the maximum number of tokens an input text is transformed for model training."),(0,a.yg)("p",null,"A higher token count leads to higher memory usage that slows down training while increasing the probability of obtaining a higher accuracy value."),(0,a.yg)("p",null,"In case of Causal Language Modeling, this includes both prompt and answer, or all prompts and answers in case of chained samples. "),(0,a.yg)("p",null,"In Sequence to Sequence Modeling, this refers to the length of the prompt, or the length of a full chained sample."))}se.isMDXComponent=!0;const pe={toc:[]},ge="wrapper";function de(e){let{components:t,...n}=e;return(0,a.yg)(ge,(0,o.A)({},pe,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Adds system, prompt and answer tokens as new tokens to the tokenizer. It is recommended to also set ",(0,a.yg)("inlineCode",{parentName:"p"},"Force Embedding Gradients")," in this case."))}de.isMDXComponent=!0;const me={toc:[]},ue="wrapper";function ce(e){let{components:t,...n}=e;return(0,a.yg)(ue,(0,o.A)({},me,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the padding quantile H2O LLM Studio uses to select the maximum token length per batch. H2O LLM Studio performs padding of shorter sequences up to the specified padding quantile instead of the selected ",(0,a.yg)("strong",{parentName:"p"},"Max length"),". H2O LLM Studio truncates longer sequences."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Lowering the quantile can significantly increase training runtime and reduce memory usage in unevenly distributed sequence lengths but can hurt performance "),(0,a.yg)("li",{parentName:"ul"},"The setting depends on the batch size and should be adjusted accordingly "),(0,a.yg)("li",{parentName:"ul"},"No padding is done in inference, and the selected ",(0,a.yg)("strong",{parentName:"li"},"Max Length")," is guaranteed"),(0,a.yg)("li",{parentName:"ul"},"Setting to 0 disables padding"),(0,a.yg)("li",{parentName:"ul"},"In case of distributed training, the quantile will be calculated across all GPUs")))}ce.isMDXComponent=!0;const ye={toc:[]},he="wrapper";function fe(e){let{components:t,...n}=e;return(0,a.yg)(he,(0,o.A)({},ye,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Whether or not to use a Fast tokenizer if possible. Some LLM backbones only offer certain types of tokenizers and changing this setting might be needed."))}fe.isMDXComponent=!0;const ve={toc:[]},be="wrapper";function Te(e){let{components:t,...n}=e;return(0,a.yg)(be,(0,o.A)({},ve,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The datatype of the weights in the LLM backbone."))}Te.isMDXComponent=!0;const xe={toc:[]},we="wrapper";function Me(e){let{components:t,...n}=e;return(0,a.yg)(we,(0,o.A)({},xe,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Determines whether H2O LLM Studio activates gradient checkpointing (GC) when training the model. Starting GC reduces the video random access memory (VRAM) footprint at the cost of a longer runtime (an additional forward pass). Turning ",(0,a.yg)("strong",{parentName:"p"},"On")," GC enables it during the training process."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Caution"),"\nGradient checkpointing is an experimental setting that is not compatible with all backbones or all other settings."),(0,a.yg)("p",null,"Activating ",(0,a.yg)("em",{parentName:"p"},"GC")," comes at the cost of a longer training time; for that reason, try training without ",(0,a.yg)("em",{parentName:"p"},"GC")," first and only activate when experiencing ",(0,a.yg)("em",{parentName:"p"},"GPU out-of-memory (OOM)")," errors."))}Me.isMDXComponent=!0;const De={toc:[]},Le="wrapper";function Ne(e){let{components:t,...n}=e;return(0,a.yg)(Le,(0,o.A)({},De,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Whether to force the computation of gradients for the input embeddings during training. Useful for LORA."))}Ne.isMDXComponent=!0;const Se={toc:[]},Ae="wrapper";function Xe(e){let{components:t,...n}=e;return(0,a.yg)(Ae,(0,o.A)({},Se,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the custom dropout rate H2O LLM Studio uses for intermediate layers in the transformer model."))}Xe.isMDXComponent=!0;const ke={toc:[]},Ce="wrapper";function Oe(e){let{components:t,...n}=e;return(0,a.yg)(Ce,(0,o.A)({},ke,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Allows you to specify a local path to the pretrained weights."))}Oe.isMDXComponent=!0;const Pe={toc:[]},ze="wrapper";function Ee(e){let{components:t,...n}=e;return(0,a.yg)(ze,(0,o.A)({},Pe,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the algorithm or method (optimizer) to use for model training. The selected algorithm or method defines how the model should change the attributes of the neural network, such as weights and learning rate. Optimizers solve optimization problems and make more accurate updates to attributes to reduce learning losses."),(0,a.yg)("p",null,"Options:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Adadelta"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"To learn about Adadelta, see ",(0,a.yg)("a",{href:"https://arxiv.org/abs/1212.5701",target:"_blank"},"ADADELTA: An Adaptive Learning Rate Method"),". "))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Adam"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"To learn about Adam, see ",(0,a.yg)("a",{href:"https://arxiv.org/abs/1412.6980",target:"_blank"},"Adam: A Method for Stochastic Optimization"),". "))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"AdamW"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"To learn about AdamW, see ",(0,a.yg)("a",{href:"https://arxiv.org/abs/1711.05101",target:"_blank"},"Decoupled Weight Decay Regularization"),"."))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"AdamW8bit"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"To learn about AdamW, see ",(0,a.yg)("a",{href:"https://arxiv.org/abs/1711.05101",target:"_blank"},"Decoupled Weight Decay Regularization"),"."))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"RMSprop")," ",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"To learn about RMSprop, see ",(0,a.yg)("a",{href:"https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf",target:"_blank"},"Neural Networks for Machine Learning"),"."))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"SGD")," ",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio uses a stochastic gradient descent optimizer.")))))}Ee.isMDXComponent=!0;const He={toc:[]},Ge="wrapper";function Ie(e){let{components:t,...n}=e;return(0,a.yg)(Ge,(0,o.A)({},He,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the loss function H2O LLM Studio utilizes during model training. The loss function is a differentiable function measuring the prediction error. The model utilizes gradients of the loss function to update the model weights during training. The options depend on the selected Problem Type."))}Ie.isMDXComponent=!0;const Re={toc:[]},qe="wrapper";function Ue(e){let{components:t,...n}=e;return(0,a.yg)(qe,(0,o.A)({},Re,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the learning rate H2O LLM Studio uses when training the model, specifically when updating the neural network's weights. The learning rate is the speed at which the model updates its weights after processing each mini-batch of data."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Learning rate is an important setting to tune as it balances under- and overfitting."),(0,a.yg)("li",{parentName:"ul"},"The number of epochs highly impacts the optimal value of the learning rate.")))}Ue.isMDXComponent=!0;const je={toc:[]},We="wrapper";function Fe(e){let{components:t,...n}=e;return(0,a.yg)(We,(0,o.A)({},je,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"If enabled, Flash Attention 2 will be used to compute the attention. Otherwise, the attention will be computed using the standard attention mechanism. "),(0,a.yg)("p",null,"Flash Attention 2 is a new attention mechanism that is faster and more memory efficient than the standard attention mechanism. Only newer GPUs support this feature."),(0,a.yg)("p",null,"See ",(0,a.yg)("a",{parentName:"p",href:"https://arxiv.org/abs/2205.14135"},"https://arxiv.org/abs/2205.14135")," for more details."))}Fe.isMDXComponent=!0;const Be={toc:[]},Ke="wrapper";function _e(e){let{components:t,...n}=e;return(0,a.yg)(Ke,(0,o.A)({},Be,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the number of training examples a mini-batch uses during an iteration of the training model to estimate the error gradient before updating the model weights. ",(0,a.yg)("strong",{parentName:"p"},"Batch size")," defines the batch size used per a single GPU."),(0,a.yg)("p",null,"During model training, the training data is packed into mini-batches of a fixed size."))}_e.isMDXComponent=!0;const Ve={toc:[]},Ye="wrapper";function Qe(e){let{components:t,...n}=e;return(0,a.yg)(Ye,(0,o.A)({},Ve,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the number of epochs to train the model. In other words, it specifies the number of times the learning algorithm goes through the entire training dataset."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"The ",(0,a.yg)("strong",{parentName:"li"},"Epochs")," setting is an important setting to tune because it balances under- and overfitting."),(0,a.yg)("li",{parentName:"ul"},"The learning rate highly impacts the optimal value of the epochs."),(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio enables you to utilize a pre-trained model trained on zero epochs (where H2O LLM Studio does not train the model and the pretrained model (experiment) can be evaluated as-is):")))}Qe.isMDXComponent=!0;const Je={toc:[]},Ze="wrapper";function $e(e){let{components:t,...n}=e;return(0,a.yg)(Ze,(0,o.A)({},Je,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the learning rate schedule H2O LLM Studio utilizes during model training. Specifying a learning rate schedule prevents the learning rate from staying the same. Instead, a learning rate schedule causes the learning rate to change over iterations, typically decreasing the learning rate to achieve a better model performance and training convergence."),(0,a.yg)("p",null,"Options"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Constant"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio applies a constant learning rate during the training process."))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Cosine"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio applies a cosine learning rate that follows the values of the cosine function."))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Linear"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio applies a linear learning rate that decreases the learning rate linearly.")))))}$e.isMDXComponent=!0;const et={toc:[]},tt="wrapper";function nt(e){let{components:t,...n}=e;return(0,a.yg)(tt,(0,o.A)({},et,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the number of epochs to warm up the learning rate where the learning rate should increase linearly from 0 to the desired learning rate. Can be a fraction of an epoch."))}nt.isMDXComponent=!0;const ot={toc:[]},at="wrapper";function it(e){let{components:t,...n}=e;return(0,a.yg)(at,(0,o.A)({},ot,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the weight decay that H2O LLM Studio uses for the optimizer during model training."),(0,a.yg)("p",null,"Weight decay is a regularization technique that adds an L2 norm of all model weights to the loss function while increasing the probability of improving the model generalization."))}it.isMDXComponent=!0;const rt={toc:[]},lt="wrapper";function st(e){let{components:t,...n}=e;return(0,a.yg)(lt,(0,o.A)({},rt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the maximum norm of the gradients H2O LLM Studio specifies during model training. Defaults to ",(0,a.yg)("strong",{parentName:"p"},"0"),", no clipping. When a value greater than 0 is specified, H2O LLM Studio modifies the gradients during model training. H2O LLM Studio uses the specified value as an upper limit for the norm of the gradients, calculated using the Euclidean norm over all gradients per batch."),(0,a.yg)("p",null,"This setting can help model convergence when extreme gradient values cause high volatility of weight updates."))}st.isMDXComponent=!0;const pt={toc:[]},gt="wrapper";function dt(e){let{components:t,...n}=e;return(0,a.yg)(gt,(0,o.A)({},pt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the number of gradient accumulations before H2O LLM Studio updates the neural network weights during model training."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Grad accumulation can be beneficial if only small batches are selected for training. With gradient accumulation, the loss and gradients are calculated after each batch, but it waits for the selected accumulations before updating the model weights. You can control the batch size through the ",(0,a.yg)("strong",{parentName:"li"},"Batch size")," setting."),(0,a.yg)("li",{parentName:"ul"},"Changing the default value of ",(0,a.yg)("em",{parentName:"li"},"Grad Accumulation")," might require adjusting the learning rate and batch size.")))}dt.isMDXComponent=!0;const mt={toc:[]},ut="wrapper";function ct(e){let{components:t,...n}=e;return(0,a.yg)(ut,(0,o.A)({},mt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Whether to use low rank approximations (LoRA) during training."))}ct.isMDXComponent=!0;const yt={toc:[]},ht="wrapper";function ft(e){let{components:t,...n}=e;return(0,a.yg)(ht,(0,o.A)({},yt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The dimension of the matrix decomposition used in LoRA."))}ft.isMDXComponent=!0;const vt={toc:[]},bt="wrapper";function Tt(e){let{components:t,...n}=e;return(0,a.yg)(bt,(0,o.A)({},vt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The scaling factor for the lora weights."))}Tt.isMDXComponent=!0;const xt={toc:[]},wt="wrapper";function Mt(e){let{components:t,...n}=e;return(0,a.yg)(wt,(0,o.A)({},xt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The probability of applying dropout to the LoRA weights during training."))}Mt.isMDXComponent=!0;const Dt={toc:[]},Lt="wrapper";function Nt(e){let{components:t,...n}=e;return(0,a.yg)(Lt,(0,o.A)({},Dt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The modules in the model to apply the LoRA approximation to. Defaults to all linear layers."))}Nt.isMDXComponent=!0;const St={toc:[]},At="wrapper";function Xt(e){let{components:t,...n}=e;return(0,a.yg)(At,(0,o.A)({},St,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Determines if H2O LLM Studio should save the model weights of the epoch exhibiting the best validation metric. When turned ",(0,a.yg)("strong",{parentName:"p"},"On"),", H2O LLM Studio saves the model weights for the epoch exhibiting the best validation metric. When turned ",(0,a.yg)("strong",{parentName:"p"},"Off"),", H2O LLM Studio saves the model weights after the last epoch is executed."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"This setting should be turned ",(0,a.yg)("strong",{parentName:"li"},"On")," with care as it has the potential to lead to overfitting of the validation data. "),(0,a.yg)("li",{parentName:"ul"},"The default goal should be to attempt to tune models so that the last or very last epoch is the best epoch.  "),(0,a.yg)("li",{parentName:"ul"},"Suppose an evident decline for later epochs is observed in logging. In that case, it is usually better to adjust hyperparameters, such as reducing the number of epochs or increasing regularization, instead of turning this setting ",(0,a.yg)("strong",{parentName:"li"},"On"),".")))}Xt.isMDXComponent=!0;const kt={toc:[]},Ct="wrapper";function Ot(e){let{components:t,...n}=e;return(0,a.yg)(Ct,(0,o.A)({},kt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the number of epochs H2O LLM Studio uses before each validation loop for model training. In other words, it determines the frequency (in a number of epochs) to run the model evaluation on the validation data."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Increasing the number of ",(0,a.yg)("em",{parentName:"li"},"Evaluation Epochs")," can speed up an experiment."),(0,a.yg)("li",{parentName:"ul"},"The ",(0,a.yg)("strong",{parentName:"li"},"Evaluation epochs")," setting is available only if the following setting is turned ",(0,a.yg)("strong",{parentName:"li"},"Off"),": ",(0,a.yg)("strong",{parentName:"li"},"Save Best Checkpoint"),". "),(0,a.yg)("li",{parentName:"ul"},"Can be a fraction of an epoch")))}Ot.isMDXComponent=!0;const Pt={toc:[]},zt="wrapper";function Et(e){let{components:t,...n}=e;return(0,a.yg)(zt,(0,o.A)({},Pt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"This option lets you evaluate the model before training, which can help you judge the quality of the LLM backbone before fine-tuning."))}Et.isMDXComponent=!0;const Ht={toc:[]},Gt="wrapper";function It(e){let{components:t,...n}=e;return(0,a.yg)(Gt,(0,o.A)({},Ht,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines whether the model should use the entire train and validation dataset during model training. When turned ",(0,a.yg)("strong",{parentName:"p"},"On"),", H2O LLM Studio uses the whole train dataset and validation data to train the model."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio also evaluates the model on the provided validation fold. Validation is always only on the provided validation fold."),(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio uses both datasets for model training if you provide a train and validation dataset.",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"To define a training dataset, use the ",(0,a.yg)("strong",{parentName:"li"},"Train dataframe")," setting."),(0,a.yg)("li",{parentName:"ul"},"To define a validation dataset, use the ",(0,a.yg)("strong",{parentName:"li"},"Validation dataframe")," setting."))),(0,a.yg)("li",{parentName:"ul"},"The ",(0,a.yg)("strong",{parentName:"li"},"Train validation data")," setting is only available if you turned the ",(0,a.yg)("strong",{parentName:"li"},"Save best checkpoint")," setting ",(0,a.yg)("strong",{parentName:"li"},"Off"),"."),(0,a.yg)("li",{parentName:"ul"},"Turning ",(0,a.yg)("strong",{parentName:"li"},"On")," the ",(0,a.yg)("strong",{parentName:"li"},"Train validation data")," setting should produce a model that you can expect to perform better because H2O LLM Studio trained the model on more data. Though, also note that using the entire train dataset and validation dataset generally causes the model's accuracy to be ",(0,a.yg)("em",{parentName:"li"},"overstated")," as information from the validation data is incorporated into the model during the training process.")))}It.isMDXComponent=!0;const Rt={toc:[]},qt="wrapper";function Ut(e){let{components:t,...n}=e;return(0,a.yg)(qt,(0,o.A)({},Rt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Toggle to enable Reinforcement Learning with Human Feedback."))}Ut.isMDXComponent=!0;const jt={toc:[]},Wt="wrapper";function Ft(e){let{components:t,...n}=e;return(0,a.yg)(Wt,(0,o.A)({},jt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The ",(0,a.yg)("strong",{parentName:"p"},"Reward Model")," option is gives control over the models weights that shall be used to score the active LLM during RLHF training."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Any suited huggingface model can be used here (not limited to the ones in the dropdown list)")))}Ft.isMDXComponent=!0;const Bt={toc:[]},Kt="wrapper";function _t(e){let{components:t,...n}=e;return(0,a.yg)(Kt,(0,o.A)({},Bt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Initial KL penalty coefficient (used for adaptive and linear control)."))}_t.isMDXComponent=!0;const Vt={toc:[]},Yt="wrapper";function Qt(e){let{components:t,...n}=e;return(0,a.yg)(Yt,(0,o.A)({},Vt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Target KL value for adaptive KL control."))}Qt.isMDXComponent=!0;const Jt={toc:[]},Zt="wrapper";function $t(e){let{components:t,...n}=e;return(0,a.yg)(Zt,(0,o.A)({},Jt,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Horizon for adaptive KL control."))}$t.isMDXComponent=!0;const en={toc:[]},tn="wrapper";function nn(e){let{components:t,...n}=e;return(0,a.yg)(tn,(0,o.A)({},en,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Gamma parameter for advantage calculation."))}nn.isMDXComponent=!0;const on={toc:[]},an="wrapper";function rn(e){let{components:t,...n}=e;return(0,a.yg)(an,(0,o.A)({},on,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Lambda parameter for advantage calculation."))}rn.isMDXComponent=!0;const ln={toc:[]},sn="wrapper";function pn(e){let{components:t,...n}=e;return(0,a.yg)(sn,(0,o.A)({},ln,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Range for clipping in PPO policy gradient loss."))}pn.isMDXComponent=!0;const gn={toc:[]},dn="wrapper";function mn(e){let{components:t,...n}=e;return(0,a.yg)(dn,(0,o.A)({},gn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Range for clipping values in loss calculation."))}mn.isMDXComponent=!0;const un={toc:[]},cn="wrapper";function yn(e){let{components:t,...n}=e;return(0,a.yg)(cn,(0,o.A)({},un,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Scaling factor for value loss."))}yn.isMDXComponent=!0;const hn={toc:[]},fn="wrapper";function vn(e){let{components:t,...n}=e;return(0,a.yg)(fn,(0,o.A)({},hn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Number of optimisation epochs per batch of samples."))}vn.isMDXComponent=!0;const bn={toc:[]},Tn="wrapper";function xn(e){let{components:t,...n}=e;return(0,a.yg)(Tn,(0,o.A)({},bn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Number of samples optimized inside PPO together."))}xn.isMDXComponent=!0;const wn={toc:[]},Mn="wrapper";function Dn(e){let{components:t,...n}=e;return(0,a.yg)(Mn,(0,o.A)({},wn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"This is the temperature that is used in the generate function during the PPO Rollout."))}Dn.isMDXComponent=!0;const Ln={toc:[]},Nn="wrapper";function Sn(e){let{components:t,...n}=e;return(0,a.yg)(Nn,(0,o.A)({},Ln,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"When enabled, this will offload the reward model weights to CPU when not in use. This can be useful when training on a GPU with limited memory. The weights will be moved back to the GPU when needed."))}Sn.isMDXComponent=!0;const An={toc:[]},Xn="wrapper";function kn(e){let{components:t,...n}=e;return(0,a.yg)(Xn,(0,o.A)({},An,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the random probability of the input text tokens to be randomly masked during training. "),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Increasing this setting can be helpful to avoid overfitting and apply regularization"),(0,a.yg)("li",{parentName:"ul"},"Each token is randomly replaced by a masking token based on the specified probability")))}kn.isMDXComponent=!0;const Cn={toc:[]},On="wrapper";function Pn(e){let{components:t,...n}=e;return(0,a.yg)(On,(0,o.A)({},Cn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"If ",(0,a.yg)("inlineCode",{parentName:"p"},"Parent Column")," is set, this random augmentation will skip parent concatenation during training at each parent with this specified probability."))}Pn.isMDXComponent=!0;const zn={toc:[]},En="wrapper";function Hn(e){let{components:t,...n}=e;return(0,a.yg)(En,(0,o.A)({},zn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"While training, each sample will be concatenated to a random other sample simulating unrelated chained conversations. Can be specified without using a ",(0,a.yg)("inlineCode",{parentName:"p"},"Parent Column"),"."))}Hn.isMDXComponent=!0;const Gn={toc:[]},In="wrapper";function Rn(e){let{components:t,...n}=e;return(0,a.yg)(In,(0,o.A)({},Gn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Will add noise to the input embeddings as proposed by ",(0,a.yg)("a",{parentName:"p",href:"https://arxiv.org/abs/2310.05914"},"https://arxiv.org/abs/2310.05914")," (NEFTune: Noisy Embeddings Improve Instruction Finetuning)"))}Rn.isMDXComponent=!0;const qn={toc:[]},Un="wrapper";function jn(e){let{components:t,...n}=e;return(0,a.yg)(Un,(0,o.A)({},qn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the metric to evaluate the model's performance. "),(0,a.yg)("p",null,"We provide several metric options for evaluating the performance of your model.\nIn addition to the BLEU and the Perplexity score, we offer GPT metrics that utilize the OpenAI API to determine whether\nthe predicted answer is more favorable than the ground truth answer.\nTo use these metrics, you can either export your OpenAI API key as an environment variable before starting LLM Studio,\nor you can specify it in the Settings Menu within the UI."))}jn.isMDXComponent=!0;const Wn={toc:[]},Fn="wrapper";function Bn(e){let{components:t,...n}=e;return(0,a.yg)(Fn,(0,o.A)({},Wn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the OpenAI model endpoint for the GPT metric."))}Bn.isMDXComponent=!0;const Kn={toc:[]},_n="wrapper";function Vn(e){let{components:t,...n}=e;return(0,a.yg)(_n,(0,o.A)({},Kn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The template to use for GPT-based evaluation. Note that for mt-bench, the validation dataset will be replaced accordingly; to approximate the original implementation as close as possible, we suggest to use gpt-4-0613 as the gpt judge model and use 1024 for the max length inference."))}Vn.isMDXComponent=!0;const Yn={toc:[]},Qn="wrapper";function Jn(e){let{components:t,...n}=e;return(0,a.yg)(Qn,(0,o.A)({},Yn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the min length value H2O LLM Studio uses for the generated text."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"This setting impacts the evaluation metrics and should depend on the dataset and average output sequence length that is expected to be predicted.")))}Jn.isMDXComponent=!0;const Zn={toc:[]},$n="wrapper";function eo(e){let{components:t,...n}=e;return(0,a.yg)($n,(0,o.A)({},Zn,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the max length value H2O LLM Studio uses for the generated text."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Similar to the ",(0,a.yg)("strong",{parentName:"li"},"Max Length")," setting in the ",(0,a.yg)("em",{parentName:"li"},"tokenizer settings")," section, this setting specifies the maximum number of tokens to predict for a given prediction sample."),(0,a.yg)("li",{parentName:"ul"},"This setting impacts the evaluation metrics and should depend on the dataset and average output sequence length that is expected to be predicted.")))}eo.isMDXComponent=!0;const to={toc:[]},no="wrapper";function oo(e){let{components:t,...n}=e;return(0,a.yg)(no,(0,o.A)({},to,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the size of a mini-batch uses during an iteration of the inference. ",(0,a.yg)("strong",{parentName:"p"},"Batch size")," defines the batch size used per GPU."))}oo.isMDXComponent=!0;const ao={toc:[]},io="wrapper";function ro(e){let{components:t,...n}=e;return(0,a.yg)(io,(0,o.A)({},ao,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Determines whether to sample from the next token distribution instead of choosing the token with the highest probability. If turned ",(0,a.yg)("strong",{parentName:"p"},"On"),", the next token in a predicted sequence is sampled based on the probabilities. If turned ",(0,a.yg)("strong",{parentName:"p"},"Off"),", the highest probability is always chosen."))}ro.isMDXComponent=!0;const lo={toc:[]},so="wrapper";function po(e){let{components:t,...n}=e;return(0,a.yg)(so,(0,o.A)({},lo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the number of beams to use for beam search. ",(0,a.yg)("em",{parentName:"p"},"Num Beams")," default value is 1  (a single beam); no beam search."),(0,a.yg)("p",null,"A higher ",(0,a.yg)("em",{parentName:"p"},"Num Beams")," value can increase prediction runtime while potentially improving accuracy."))}po.isMDXComponent=!0;const go={toc:[]},mo="wrapper";function uo(e){let{components:t,...n}=e;return(0,a.yg)(mo,(0,o.A)({},go,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the temperature to use for sampling from the next token distribution during validation and inference. In other words, the defined temperature controls the randomness of predictions by scaling the logits before applying ",(0,a.yg)("a",{href:"https://www.researchgate.net/figure/The-Gumbel-Softmax-distribution-interpolates-between-discrete-one-hot-encoded-categorical_fig4_309663606",target:"_blank"},"softmax"),". A higher temperature makes the distribution more random."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Modify the temperature value if you have the ",(0,a.yg)("strong",{parentName:"li"},"Do Sample")," setting enabled (",(0,a.yg)("strong",{parentName:"li"},"On"),")."),(0,a.yg)("li",{parentName:"ul"},"To learn more about this setting, refer to the following article: ",(0,a.yg)("a",{href:"https://huggingface.co/blog/how-to-generate",target:"_blank"},"How to generate text: using different decoding methods for language generation with Transformers"),".")))}uo.isMDXComponent=!0;const co={toc:[]},yo="wrapper";function ho(e){let{components:t,...n}=e;return(0,a.yg)(yo,(0,o.A)({},co,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The parameter for repetition penalty. 1.0 means no penalty. See ",(0,a.yg)("a",{parentName:"p",href:"https://arxiv.org/pdf/1909.05858.pdf"},"https://arxiv.org/pdf/1909.05858.pdf")," for more details."))}ho.isMDXComponent=!0;const fo={toc:[]},vo="wrapper";function bo(e){let{components:t,...n}=e;return(0,a.yg)(vo,(0,o.A)({},fo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Will stop generation at occurrence of these additional tokens; multiple tokens should be split by comma ",(0,a.yg)("inlineCode",{parentName:"p"},","),"."))}bo.isMDXComponent=!0;const To={toc:[]},xo="wrapper";function wo(e){let{components:t,...n}=e;return(0,a.yg)(xo,(0,o.A)({},To,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"If > 0, only keep the top k tokens with the highest probability (top-k filtering)."))}wo.isMDXComponent=!0;const Mo={toc:[]},Do="wrapper";function Lo(e){let{components:t,...n}=e;return(0,a.yg)(Do,(0,o.A)({},Mo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering)."))}Lo.isMDXComponent=!0;const No={toc:[]},So="wrapper";function Ao(e){let{components:t,...n}=e;return(0,a.yg)(So,(0,o.A)({},No,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Determines the list of GPUs H2O LLM Studio can use for the experiment. GPUs are listed by name, referring to their system ID (starting from 1)."))}Ao.isMDXComponent=!0;const Xo={toc:[]},ko="wrapper";function Co(e){let{components:t,...n}=e;return(0,a.yg)(ko,(0,o.A)({},Xo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Determines whether to use mixed-precision. When turned ",(0,a.yg)("strong",{parentName:"p"},"Off"),", H2O LLM Studio does not use mixed-precision."),(0,a.yg)("p",null,"Mixed-precision is a technique that helps decrease memory consumption and increases training speed."))}Co.isMDXComponent=!0;const Oo={toc:[]},Po="wrapper";function zo(e){let{components:t,...n}=e;return(0,a.yg)(Po,(0,o.A)({},Oo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Compiles the model with Torch. Experimental!"))}zo.isMDXComponent=!0;const Eo={toc:[]},Ho="wrapper";function Go(e){let{components:t,...n}=e;return(0,a.yg)(Ho,(0,o.A)({},Eo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"In Distributed Data Parallel (DDP) mode, ",(0,a.yg)("inlineCode",{parentName:"p"},"prepare_for_backward()")," is called at the end of DDP forward pass. It traverses the autograd graph to find unused parameters when ",(0,a.yg)("inlineCode",{parentName:"p"},"find_unused_parameters")," is set to True in DDP constructor."),(0,a.yg)("p",null,"Note that traversing the autograd graph introduces extra overheads, so applications should only set to True when necessary."))}Go.isMDXComponent=!0;const Io={toc:[]},Ro="wrapper";function qo(e){let{components:t,...n}=e;return(0,a.yg)(Ro,(0,o.A)({},Io,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Trust remote code. This can be necessary for some models that use code which is not (yet) part of the ",(0,a.yg)("inlineCode",{parentName:"p"},"transformers")," package. Should always be checked with this option being switched ",(0,a.yg)("strong",{parentName:"p"},"Off")," first."))}qo.isMDXComponent=!0;const Uo={toc:[]},jo="wrapper";function Wo(e){let{components:t,...n}=e;return(0,a.yg)(jo,(0,o.A)({},Uo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The ",(0,a.yg)("strong",{parentName:"p"},"Huggingface Branch"),' defines which branch to use in a Huggingface repository. The default value is "main".'))}Wo.isMDXComponent=!0;const Fo={toc:[]},Bo="wrapper";function Ko(e){let{components:t,...n}=e;return(0,a.yg)(Bo,(0,o.A)({},Fo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the number of workers H2O LLM Studio uses for the ",(0,a.yg)("em",{parentName:"p"},"DataLoader"),". In other words, it defines the number of CPU processes to use when reading and loading data to GPUs during model training."))}Ko.isMDXComponent=!0;const _o={toc:[]},Vo="wrapper";function Yo(e){let{components:t,...n}=e;return(0,a.yg)(Vo,(0,o.A)({},_o,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the random seed value that H2O LLM Studio uses during model training. It defaults to -1, an arbitrary value. When the value is modified (not -1), the random seed allows results to be reproducible\u2014defining a seed aids in obtaining predictable and repeatable results every time. Otherwise, not modifying the default seed value (-1) leads to random numbers at every invocation."))}Yo.isMDXComponent=!0;const Qo={toc:[]},Jo="wrapper";function Zo(e){let{components:t,...n}=e;return(0,a.yg)(Jo,(0,o.A)({},Qo,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the logger type that H2O LLM Studio uses for model training"),(0,a.yg)("p",null,"Options"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"None"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio does not use any logger."))),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Neptune"),(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},"H2O LLM Studio uses Neptune as a logger to track the experiment. To use Neptune, you must specify a ",(0,a.yg)("strong",{parentName:"li"},"Neptune API token")," and a ",(0,a.yg)("strong",{parentName:"li"},"Neptune project"),".")))))}Zo.isMDXComponent=!0;const $o={toc:[]},ea="wrapper";function ta(e){let{components:t,...n}=e;return(0,a.yg)(ea,(0,o.A)({},$o,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines the ",(0,a.yg)("a",{href:"https://neptune.ai/",target:"_blank"},"Neptune")," project to access if you selected Neptune in the ",(0,a.yg)("strong",{parentName:"p"},"Logger")," setting."))}ta.isMDXComponent=!0;const na={description:"All the settings needed for creating an experiment are explored in this page."},oa="Experiment settings",aa={unversionedId:"guide/experiments/experiment-settings",id:"guide/experiments/experiment-settings",title:"Experiment settings",description:"All the settings needed for creating an experiment are explored in this page.",source:"@site/docs/guide/experiments/experiment-settings.md",sourceDirName:"guide/experiments",slug:"/guide/experiments/experiment-settings",permalink:"/h2o-llmstudio/guide/experiments/experiment-settings",draft:!1,tags:[],version:"current",frontMatter:{description:"All the settings needed for creating an experiment are explored in this page."},sidebar:"defaultSidebar",previous:{title:"Merge datasets",permalink:"/h2o-llmstudio/guide/datasets/merge-datasets"},next:{title:"Create an experiment",permalink:"/h2o-llmstudio/guide/experiments/create-an-experiment"}},ia={},ra=[{value:"General settings",id:"general-settings",level:2},{value:"Dataset",id:"dataset",level:3},{value:"Problem type",id:"problem-type",level:3},{value:"Import config from YAML",id:"import-config-from-yaml",level:3},{value:"Experiment name",id:"experiment-name",level:3},{value:"LLM backbone",id:"llm-backbone",level:3},{value:"Dataset settings",id:"dataset-settings",level:2},{value:"Train dataframe",id:"train-dataframe",level:3},{value:"Validation strategy",id:"validation-strategy",level:3},{value:"Validation size",id:"validation-size",level:3},{value:"Data sample",id:"data-sample",level:3},{value:"System column",id:"system-column",level:3},{value:"Prompt column",id:"prompt-column",level:3},{value:"Answer column",id:"answer-column",level:3},{value:"Parent ID column",id:"parent-id-column",level:3},{value:"Text prompt start",id:"text-prompt-start",level:3},{value:"Text answer separator",id:"text-answer-separator",level:3},{value:"Adaptive Kl control",id:"adaptive-kl-control",level:2},{value:"Add EOS token to prompt",id:"add-eos-token-to-prompt",level:3},{value:"Add EOS token to answer",id:"add-eos-token-to-answer",level:3},{value:"Mask prompt labels",id:"mask-prompt-labels",level:3},{value:"Tokenizer settings",id:"tokenizer-settings",level:2},{value:"Max length prompt",id:"max-length-prompt",level:3},{value:"Max length answer",id:"max-length-answer",level:3},{value:"Max length",id:"max-length",level:3},{value:"Add prompt answer tokens",id:"add-prompt-answer-tokens",level:3},{value:"Padding quantile",id:"padding-quantile",level:3},{value:"Use fast",id:"use-fast",level:3},{value:"Architecture settings",id:"architecture-settings",level:2},{value:"Backbone Dtype",id:"backbone-dtype",level:3},{value:"Gradient Checkpointing",id:"gradient-checkpointing",level:3},{value:"Force Embedding Gradients",id:"force-embedding-gradients",level:3},{value:"Intermediate dropout",id:"intermediate-dropout",level:3},{value:"Pretrained weights",id:"pretrained-weights",level:3},{value:"Training settings",id:"training-settings",level:2},{value:"Loss function",id:"loss-function",level:3},{value:"Optimizer",id:"optimizer",level:3},{value:"Learning rate",id:"learning-rate",level:3},{value:"Use Flash Attention 2",id:"use-flash-attention-2",level:3},{value:"Batch size",id:"batch-size",level:3},{value:"Epochs",id:"epochs",level:3},{value:"Schedule",id:"schedule",level:3},{value:"Warmup epochs",id:"warmup-epochs",level:3},{value:"Weight decay",id:"weight-decay",level:3},{value:"Gradient clip",id:"gradient-clip",level:3},{value:"Grad accumulation",id:"grad-accumulation",level:3},{value:"Lora",id:"lora",level:3},{value:"Lora R",id:"lora-r",level:3},{value:"Lora Alpha",id:"lora-alpha",level:3},{value:"Lora dropout",id:"lora-dropout",level:3},{value:"Lora target modules",id:"lora-target-modules",level:3},{value:"Save best checkpoint",id:"save-best-checkpoint",level:3},{value:"Evaluation epochs",id:"evaluation-epochs",level:3},{value:"Evaluate before training",id:"evaluate-before-training",level:3},{value:"Train validation data",id:"train-validation-data",level:3},{value:"Use RLHF",id:"use-rlhf",level:3},{value:"Reward model",id:"reward-model",level:3},{value:"Adaptive KL control",id:"adaptive-kl-control-1",level:3},{value:"Initial KL coefficient",id:"initial-kl-coefficient",level:3},{value:"KL target",id:"kl-target",level:3},{value:"KL Horizon",id:"kl-horizon",level:3},{value:"Advantages gamma",id:"advantages-gamma",level:3},{value:"Advantages Lambda",id:"advantages-lambda",level:3},{value:"PPO clip policy",id:"ppo-clip-policy",level:3},{value:"PPO clip value",id:"ppo-clip-value",level:3},{value:"Scaling factor value loss",id:"scaling-factor-value-loss",level:3},{value:"PPO epochs",id:"ppo-epochs",level:3},{value:"PPO Batch Size",id:"ppo-batch-size",level:3},{value:"PPO generate temperature",id:"ppo-generate-temperature",level:3},{value:"Offload reward model",id:"offload-reward-model",level:3},{value:"Augmentation settings",id:"augmentation-settings",level:2},{value:"Token mask probability",id:"token-mask-probability",level:3},{value:"Skip parent probability",id:"skip-parent-probability",level:3},{value:"Random parent probability",id:"random-parent-probability",level:3},{value:"Neftune noise alpha",id:"neftune-noise-alpha",level:3},{value:"Prediction settings",id:"prediction-settings",level:2},{value:"Metric",id:"metric",level:3},{value:"Metric GPT model",id:"metric-gpt-model",level:3},{value:"Metric GPT template",id:"metric-gpt-template",level:3},{value:"Min length inference",id:"min-length-inference",level:3},{value:"Max length inference",id:"max-length-inference",level:3},{value:"Batch size inference",id:"batch-size-inference",level:3},{value:"Do sample",id:"do-sample",level:3},{value:"Num beams",id:"num-beams",level:3},{value:"Temperature",id:"temperature",level:3},{value:"Repetition penalty",id:"repetition-penalty",level:3},{value:"Stop tokens",id:"stop-tokens",level:3},{value:"Top K",id:"top-k",level:3},{value:"Top P",id:"top-p",level:3},{value:"Environment settings",id:"environment-settings",level:2},{value:"GPUs",id:"gpus",level:3},{value:"Mixed precision",id:"mixed-precision",level:3},{value:"Compile model",id:"compile-model",level:3},{value:"Find unused parameters",id:"find-unused-parameters",level:3},{value:"Trust remote code",id:"trust-remote-code",level:3},{value:"Huggingface branch",id:"huggingface-branch",level:3},{value:"Number of workers",id:"number-of-workers",level:3},{value:"Seed",id:"seed",level:3},{value:"Logging settings",id:"logging-settings",level:2},{value:"Logger",id:"logger",level:3},{value:"Neptune project",id:"neptune-project",level:3}],la={toc:ra},sa="wrapper";function pa(e){let{components:t,...n}=e;return(0,a.yg)(sa,(0,o.A)({},la,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"experiment-settings"},"Experiment settings"),(0,a.yg)("p",null,"The settings for creating an experiment are grouped into the following sections: "),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#general-settings"},"General settings")," "),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#dataset-settings"},"Dataset settings")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#tokenizer-settings"},"Tokenizer settings")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#architecture-settings"},"Architecture settings")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#training-settings"},"Training settings")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#augmentation-settings"},"Augmentation settings")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#prediction-settings"},"Prediction settings")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#environment-settings"},"Environment settings")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#logging-settings"},"Logging settings"))),(0,a.yg)("p",null,"The settings under each category are listed and described below."),(0,a.yg)("h2",{id:"general-settings"},"General settings"),(0,a.yg)("h3",{id:"dataset"},"Dataset"),(0,a.yg)(l,{mdxType:"GeneralSettingsDataset"}),(0,a.yg)("h3",{id:"problem-type"},"Problem type"),(0,a.yg)(g,{mdxType:"GeneralSettingsProblemType"}),(0,a.yg)("h3",{id:"import-config-from-yaml"},"Import config from YAML"),(0,a.yg)(u,{mdxType:"GSImportConfigFromYaml"}),(0,a.yg)("h3",{id:"experiment-name"},"Experiment name"),(0,a.yg)(h,{mdxType:"GSExperimentName"}),(0,a.yg)("h3",{id:"llm-backbone"},"LLM backbone"),(0,a.yg)(b,{mdxType:"GSLLMBackbone"}),(0,a.yg)("h2",{id:"dataset-settings"},"Dataset settings"),(0,a.yg)("h3",{id:"train-dataframe"},"Train dataframe"),(0,a.yg)(T.Ay,{mdxType:"DSTrainDataframe"}),(0,a.yg)("h3",{id:"validation-strategy"},"Validation strategy"),(0,a.yg)(M,{mdxType:"DSvalidationStrategy"}),(0,a.yg)("h3",{id:"validation-size"},"Validation size"),(0,a.yg)(N,{mdxType:"DSvalidationSize"}),(0,a.yg)("h3",{id:"data-sample"},"Data sample"),(0,a.yg)(X,{mdxType:"DSdataSample"}),(0,a.yg)("h3",{id:"system-column"},"System column"),(0,a.yg)(P,{mdxType:"DSsystemColumn"}),(0,a.yg)("h3",{id:"prompt-column"},"Prompt column"),(0,a.yg)(k.Ay,{mdxType:"DSpromptColumn"}),(0,a.yg)("h3",{id:"answer-column"},"Answer column"),(0,a.yg)(z.Ay,{mdxType:"DSanswerColumn"}),(0,a.yg)("h3",{id:"parent-id-column"},"Parent ID column"),(0,a.yg)(E.Ay,{mdxType:"DSparentIdColumn"}),(0,a.yg)("h3",{id:"text-prompt-start"},"Text prompt start"),(0,a.yg)(I,{mdxType:"DStextPromptStart"}),(0,a.yg)("h3",{id:"text-answer-separator"},"Text answer separator"),(0,a.yg)(U,{mdxType:"DStextAnswerSeparator"}),(0,a.yg)("h2",{id:"adaptive-kl-control"},"Adaptive Kl control"),(0,a.yg)(F,{mdxType:"DSadaptiveKlControl"}),(0,a.yg)("h3",{id:"add-eos-token-to-prompt"},"Add EOS token to prompt"),(0,a.yg)(_,{mdxType:"DSaddEosTokentoprompt"}),(0,a.yg)("h3",{id:"add-eos-token-to-answer"},"Add EOS token to answer"),(0,a.yg)(Q,{mdxType:"DSaddEosTokentoanswer"}),(0,a.yg)("h3",{id:"mask-prompt-labels"},"Mask prompt labels"),(0,a.yg)($,{mdxType:"DSmaskPromptlabels"}),(0,a.yg)("h2",{id:"tokenizer-settings"},"Tokenizer settings"),(0,a.yg)("h3",{id:"max-length-prompt"},"Max length prompt"),(0,a.yg)(ne,{mdxType:"TSmaxLengthPrompt"}),(0,a.yg)("h3",{id:"max-length-answer"},"Max length answer"),(0,a.yg)(ie,{mdxType:"TSmaxLengthAnswer"}),(0,a.yg)("h3",{id:"max-length"},"Max length"),(0,a.yg)(se,{mdxType:"TSmaxLength"}),(0,a.yg)("h3",{id:"add-prompt-answer-tokens"},"Add prompt answer tokens"),(0,a.yg)(de,{mdxType:"TSaddpromptanswertokens"}),(0,a.yg)("h3",{id:"padding-quantile"},"Padding quantile"),(0,a.yg)(ce,{mdxType:"TSpaddingQuantile"}),(0,a.yg)("h3",{id:"use-fast"},"Use fast"),(0,a.yg)(fe,{mdxType:"TSuseFast"}),(0,a.yg)("h2",{id:"architecture-settings"},"Architecture settings"),(0,a.yg)("h3",{id:"backbone-dtype"},"Backbone Dtype"),(0,a.yg)(Te,{mdxType:"ASBackboneDtype"}),(0,a.yg)("h3",{id:"gradient-checkpointing"},"Gradient Checkpointing"),(0,a.yg)(Me,{mdxType:"ASGradientcheckpointing"}),(0,a.yg)("h3",{id:"force-embedding-gradients"},"Force Embedding Gradients"),(0,a.yg)(Ne,{mdxType:"ASforceEmbeddingGradients"}),(0,a.yg)("h3",{id:"intermediate-dropout"},"Intermediate dropout"),(0,a.yg)(Xe,{mdxType:"ASintermediateDropout"}),(0,a.yg)("h3",{id:"pretrained-weights"},"Pretrained weights"),(0,a.yg)(Oe,{mdxType:"ASpretrainedWeights"}),(0,a.yg)("h2",{id:"training-settings"},"Training settings"),(0,a.yg)("h3",{id:"loss-function"},"Loss function"),(0,a.yg)(Ie,{mdxType:"TSlossfunction"}),(0,a.yg)("h3",{id:"optimizer"},"Optimizer"),(0,a.yg)(Ee,{mdxType:"TSoptimizer"}),(0,a.yg)("h3",{id:"learning-rate"},"Learning rate"),(0,a.yg)(Ue,{mdxType:"TSlearningRate"}),(0,a.yg)("h3",{id:"use-flash-attention-2"},"Use Flash Attention 2"),(0,a.yg)(Fe,{mdxType:"TSuseflashattention2"}),(0,a.yg)("h3",{id:"batch-size"},"Batch size"),(0,a.yg)(_e,{mdxType:"TSbatchSize"}),(0,a.yg)("h3",{id:"epochs"},"Epochs"),(0,a.yg)(Qe,{mdxType:"TSepochs"}),(0,a.yg)("h3",{id:"schedule"},"Schedule"),(0,a.yg)($e,{mdxType:"TSschedule"}),(0,a.yg)("h3",{id:"warmup-epochs"},"Warmup epochs"),(0,a.yg)(nt,{mdxType:"TSwarmupEpochs"}),(0,a.yg)("h3",{id:"weight-decay"},"Weight decay"),(0,a.yg)(it,{mdxType:"TSweightDecay"}),(0,a.yg)("h3",{id:"gradient-clip"},"Gradient clip"),(0,a.yg)(st,{mdxType:"TSGradientclip"}),(0,a.yg)("h3",{id:"grad-accumulation"},"Grad accumulation"),(0,a.yg)(dt,{mdxType:"TSgradAccumulation"}),(0,a.yg)("h3",{id:"lora"},"Lora"),(0,a.yg)(ct,{mdxType:"TSlora"}),(0,a.yg)("h3",{id:"lora-r"},"Lora R"),(0,a.yg)(ft,{mdxType:"TSloraR"}),(0,a.yg)("h3",{id:"lora-alpha"},"Lora Alpha"),(0,a.yg)(Tt,{mdxType:"TSloraAlpha"}),(0,a.yg)("h3",{id:"lora-dropout"},"Lora dropout"),(0,a.yg)(Mt,{mdxType:"TSloraDropout"}),(0,a.yg)("h3",{id:"lora-target-modules"},"Lora target modules"),(0,a.yg)(Nt,{mdxType:"TSloraTargetModules"}),(0,a.yg)("h3",{id:"save-best-checkpoint"},"Save best checkpoint"),(0,a.yg)(Xt,{mdxType:"TSsavebestcheckpoint"}),(0,a.yg)("h3",{id:"evaluation-epochs"},"Evaluation epochs"),(0,a.yg)(Ot,{mdxType:"TSevaluationepochs"}),(0,a.yg)("h3",{id:"evaluate-before-training"},"Evaluate before training"),(0,a.yg)(Et,{mdxType:"TSevaluationbeforetraining"}),(0,a.yg)("h3",{id:"train-validation-data"},"Train validation data"),(0,a.yg)(It,{mdxType:"TStrainvalidationdata"}),(0,a.yg)("h3",{id:"use-rlhf"},"Use RLHF"),(0,a.yg)(Ut,{mdxType:"TSuseRHLF"}),(0,a.yg)("h3",{id:"reward-model"},"Reward model"),(0,a.yg)(Ft,{mdxType:"TSrewardModel"}),(0,a.yg)("h3",{id:"adaptive-kl-control-1"},"Adaptive KL control"),(0,a.yg)(F,{mdxType:"DSadaptiveKlControl"}),(0,a.yg)("h3",{id:"initial-kl-coefficient"},"Initial KL coefficient"),(0,a.yg)(_t,{mdxType:"TSinitialKlCoefficient"}),(0,a.yg)("h3",{id:"kl-target"},"KL target"),(0,a.yg)(Qt,{mdxType:"TSklTarget"}),(0,a.yg)("h3",{id:"kl-horizon"},"KL Horizon"),(0,a.yg)($t,{mdxType:"TSklHorizon"}),(0,a.yg)("h3",{id:"advantages-gamma"},"Advantages gamma"),(0,a.yg)(nn,{mdxType:"TSadvantagesGamma"}),(0,a.yg)("h3",{id:"advantages-lambda"},"Advantages Lambda"),(0,a.yg)(rn,{mdxType:"TSadvantagesLambda"}),(0,a.yg)("h3",{id:"ppo-clip-policy"},"PPO clip policy"),(0,a.yg)(pn,{mdxType:"TSppoClipPolicy"}),(0,a.yg)("h3",{id:"ppo-clip-value"},"PPO clip value"),(0,a.yg)(mn,{mdxType:"TSppoClipValue"}),(0,a.yg)("h3",{id:"scaling-factor-value-loss"},"Scaling factor value loss"),(0,a.yg)(yn,{mdxType:"TSscalingFactorValueLoss"}),(0,a.yg)("h3",{id:"ppo-epochs"},"PPO epochs"),(0,a.yg)(vn,{mdxType:"TSppoEpochs"}),(0,a.yg)("h3",{id:"ppo-batch-size"},"PPO Batch Size"),(0,a.yg)(xn,{mdxType:"TSppoBatchSize"}),(0,a.yg)("h3",{id:"ppo-generate-temperature"},"PPO generate temperature"),(0,a.yg)(Dn,{mdxType:"TSppoGenerateTemp"}),(0,a.yg)("h3",{id:"offload-reward-model"},"Offload reward model"),(0,a.yg)(Sn,{mdxType:"TSoffloadRewardModel"}),(0,a.yg)("h2",{id:"augmentation-settings"},"Augmentation settings"),(0,a.yg)("h3",{id:"token-mask-probability"},"Token mask probability"),(0,a.yg)(kn,{mdxType:"AStokenmaskprobability"}),(0,a.yg)("h3",{id:"skip-parent-probability"},"Skip parent probability"),(0,a.yg)(Pn,{mdxType:"ASskipParentprobability"}),(0,a.yg)("h3",{id:"random-parent-probability"},"Random parent probability"),(0,a.yg)(Hn,{mdxType:"ASrandomparentprobability"}),(0,a.yg)("h3",{id:"neftune-noise-alpha"},"Neftune noise alpha"),(0,a.yg)(Rn,{mdxType:"ASneftunenoisealpha"}),(0,a.yg)("h2",{id:"prediction-settings"},"Prediction settings"),(0,a.yg)("h3",{id:"metric"},"Metric"),(0,a.yg)(jn,{mdxType:"PSmetric"}),(0,a.yg)("h3",{id:"metric-gpt-model"},"Metric GPT model"),(0,a.yg)(Bn,{mdxType:"PSmetricgptmodel"}),(0,a.yg)("h3",{id:"metric-gpt-template"},"Metric GPT template"),(0,a.yg)(Vn,{mdxType:"PSmetricgpttemplate"}),(0,a.yg)("h3",{id:"min-length-inference"},"Min length inference"),(0,a.yg)(Jn,{mdxType:"PSminlengthinference"}),(0,a.yg)("h3",{id:"max-length-inference"},"Max length inference"),(0,a.yg)(eo,{mdxType:"PSmaxlengthinference"}),(0,a.yg)("h3",{id:"batch-size-inference"},"Batch size inference"),(0,a.yg)(oo,{mdxType:"PSbatchsizeinference"}),(0,a.yg)("h3",{id:"do-sample"},"Do sample"),(0,a.yg)(ro,{mdxType:"PSdosample"}),(0,a.yg)("h3",{id:"num-beams"},"Num beams"),(0,a.yg)(po,{mdxType:"PSnumbeams"}),(0,a.yg)("h3",{id:"temperature"},"Temperature"),(0,a.yg)(uo,{mdxType:"PStemperature"}),(0,a.yg)("h3",{id:"repetition-penalty"},"Repetition penalty"),(0,a.yg)(ho,{mdxType:"PSrepetitionpenalty"}),(0,a.yg)("h3",{id:"stop-tokens"},"Stop tokens"),(0,a.yg)(bo,{mdxType:"PSstoptokens"}),(0,a.yg)("h3",{id:"top-k"},"Top K"),(0,a.yg)(wo,{mdxType:"PStopk"}),(0,a.yg)("h3",{id:"top-p"},"Top P"),(0,a.yg)(Lo,{mdxType:"PStopp"}),(0,a.yg)("h2",{id:"environment-settings"},"Environment settings"),(0,a.yg)("h3",{id:"gpus"},"GPUs"),(0,a.yg)(Ao,{mdxType:"ESgpus"}),(0,a.yg)("h3",{id:"mixed-precision"},"Mixed precision"),(0,a.yg)(Co,{mdxType:"ESmixedprecision"}),(0,a.yg)("h3",{id:"compile-model"},"Compile model"),(0,a.yg)(zo,{mdxType:"EScompilemodel"}),(0,a.yg)("h3",{id:"find-unused-parameters"},"Find unused parameters"),(0,a.yg)(Go,{mdxType:"ESfindunusedparameters"}),(0,a.yg)("h3",{id:"trust-remote-code"},"Trust remote code"),(0,a.yg)(qo,{mdxType:"EStrustremotecode"}),(0,a.yg)("h3",{id:"huggingface-branch"},"Huggingface branch"),(0,a.yg)(Wo,{mdxType:"EShuggingfacebranch"}),(0,a.yg)("h3",{id:"number-of-workers"},"Number of workers"),(0,a.yg)(Ko,{mdxType:"ESnumofworkers"}),(0,a.yg)("h3",{id:"seed"},"Seed"),(0,a.yg)(Yo,{mdxType:"ESseed"}),(0,a.yg)("h2",{id:"logging-settings"},"Logging settings"),(0,a.yg)("h3",{id:"logger"},"Logger"),(0,a.yg)(Zo,{mdxType:"LSlogger"}),(0,a.yg)("h3",{id:"neptune-project"},"Neptune project"),(0,a.yg)(ta,{mdxType:"LSneptuneproject"}))}pa.isMDXComponent=!0},5690:(e,t,n)=>{n.d(t,{Ay:()=>l});var o=n(8168),a=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.yg)(r,(0,o.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The column in the dataset containing the expected output."),(0,a.yg)("p",null,"For classification, this needs to be an integer column containing the class label."))}l.isMDXComponent=!0},5482:(e,t,n)=>{n.d(t,{Ay:()=>l});var o=n(8168),a=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.yg)(r,(0,o.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"An optional column specifying the parent id to be used for chained conversations. The value of this column needs to match an additional column with the name ",(0,a.yg)("inlineCode",{parentName:"p"},"id"),". If provided, the prompt will be concatenated after preceeding parent rows."))}l.isMDXComponent=!0},5886:(e,t,n)=>{n.d(t,{Ay:()=>l});var o=n(8168),a=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.yg)(r,(0,o.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"The column in the dataset containing the user prompt."))}l.isMDXComponent=!0},3385:(e,t,n)=>{n.d(t,{Ay:()=>l});var o=n(8168),a=(n(6540),n(5680));const i={toc:[]},r="wrapper";function l(e){let{components:t,...n}=e;return(0,a.yg)(r,(0,o.A)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"Defines a ",(0,a.yg)("inlineCode",{parentName:"p"},".csv")," or ",(0,a.yg)("inlineCode",{parentName:"p"},".pq")," file containing a dataframe with training records that H2O LLM Studio uses to ",(0,a.yg)("em",{parentName:"p"},"train")," the model."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"The records are combined into mini-batches when training the model.")))}l.isMDXComponent=!0}}]);